ChatGPT带来的巨大范式转移，意味着什么？
=======================

[www.36kr.com](https://www.36kr.com/p/2157109939953666)关注

ChatGPT"晕菜"了。

去年第一次跟ChatGPT对话时，周伯文特意给它出了一道难题："我的朋友比他领导大10个月，他们现在结婚3年了，请问结婚50年时他比他的领导大几个月？"

ChatGPT也的确被这个脑筋急转弯似的简单推理难住了，"它一五一十地跟我分析计算，大意是现在大10个月，结婚3年了，离他们结婚50年还有47年，一年有12个月，47×12等于多少，再加上10个月，那时候他会比他的领导大400多个月。"

周伯文是清华大学惠妍讲席教授、清华大学电子工程系长聘教授和协同交互智能研究中心主任、[衔远科技](https://36kr.com/project/2151645004355585)创始人，由于长期研究自然语言、大模型和人机对话相关技术，他清楚地知道当前技术的优势和短板。周伯文表示，目前写作和总结类相关问题，ChatGPT可以有理有据地高情商回答，但一旦涉及到知识与推理的结合，它的短板就显现出来了。

尽管如此，周伯文依然非常看好ChatGPT的前景，"我们对ChatGPT的态度是'到来不吃惊，影响不低估，未来有办法'。"

目前ChatGPT的应用非常广泛，这背后需要大量的数据和算力去支持大模型。在周伯文看来，虽然国内资金充裕和能力十足的大厂纷纷下场，但受限于自身业务发展，而且也会经历一个较长的研发时间，再加上大厂在公司发展决策上的种种顾虑，比如管理层和技术leader的认知和预期是否一致，还要考虑股价、投资回报率等，究竟谁（的大模型）能跑出来现在要打一个问号。

周伯文也提出了另一条可行的路径，"我认为在垂直领域里结合应用端到端的去训练、逐步发展为大模型的模式是一条值得重视与探索的路，尤其是对创业公司来说。因为目前的市场足够大，创业公司只要先做好一个垂直领域，帮助自有的大模型带来数据、场景的闭环，也因为客户价值清晰明确，有明确的付费模式支持，模型越来越强大的路径就会打通。"

近日，周伯文在与《中国企业家》的一次内部交流中，发表了主题演讲《When we chat about ChatGPT，what do we chat about？》，主要介绍了协同交互智能与多模态学习领域内的最新进展，与对ChatGPT在未来产业应用的展望。

**本次演讲要点包括：**

1.ChatGPT的出现是必然的，OpenAI这家公司首先做出来则是有一定偶然性的。

2.ChatGPT还远远不到通用人工智能的程度，其推理、知识等能力存在明显短板。

3.ChatGPT第一次实现了人跟AI多轮协同共创，这带来了一个巨大的范式转移。一旦范式成立，会形成一种人工智能推动新知识发现的新飞轮。

4.研发通用大模型的成本非常高而且是一个不断提升的移动目标，从垂直大模型加场景端到端做起，慢慢迭代出更大的商业模型，或许是创业公司更适合的做法。

5.AI的下一个突破会从纯虚拟的存在转到帮助人在物理世界、生物世界和信息世界里更高效洞察、形成新知识并完成任务，创造更高价值场景。

**以下为演讲内容，有删减。**

**ChatGPT的短板与长处**
-----------------

对于我们业界研究的人而言，我们很早就预见了AI能力的涌现。AI的发展是有一个长链条存在的，从机器学习到神经网络到深度学习，到Transformer模型，再到GPT-3，InstructGPT，一直到ChatGPT，整个路径非常清晰，所以ChatGPT的出现并不是一件完全不可预见的事情。

即使没有OpenAI，AI能力技术也会在这一两年里涌现，所以我认为ChatGPT的出现是必然的，OpenAI这家公司做出来则是有一定偶然性的。

OpenAI为什么能做出ChatGPT呢？

我认为，虽然这个工作本身是OpenAI自己参与，但绝对离不开整个学术社区的帮助。

像我们说的Transformer模型，就是基于多头自注意力等学术理论的进一步深入，并在成功后获得更多研究分析其机理的合理性。这些学术社区的研究验证了大模型在被大量数据训练后，确实能存储丰富的知识了，它的表现就不是随机生成的过拟合。这些进展让公司更有勇气砸大量金钱去训练模型，一定需要证据证明方向是正确的，而这些研究就是一个非常好的证据。

另外，**还一定要有竞争，如果GPT模型没有跟同期的BERT（Google的预训练模型）模型长期竞争，它的进展不会这么快。**

ChatGPT还对两个理论进行了验证，一个是数据越多，能力越强，就是线性放大的理论"Scaling Laws"；另一个是"能力涌现"，就是模型大到一定程度后，它就会突然开始融会贯通了。

但在我看来，ChatGPT还远远不到通用人工智能的程度。ChatGPT证明了通过大量的无监督学习的有效性。但人工智能要更具通用性，还需要具备知识、计算、推理这三种能力的组合能力。

ChatGPT目前做得比较好的是计算，在推理上也出现了一些能力涌现，但复杂推理的程度比较低。比如说人可以进行多跳推理，直接从a推导出c来。但ChatGPT的推理能力在两跳以上后，它就会迅速降低到20%的准确率，因此我说这个能力还远远不够。知识层面，目前ChatGPT的知识是不完备的。

ChatGPT的第二个短板，就是模型越大并不一定意味着越好。当训练模型规模达到一定界限时，AI在某些任务上的表现反而会下降。因为目前AI真正的想象力和推理能力有很大的缺陷，一旦投喂数据越多，模型越大，它的思维和创造力就会被固化了。

ChatGPT能做到现在这个地步，除了底层大模型的能力涌现之外，它有一个非常主要的贡献，就是通过人的协同和交互来加强AI的能力。

举个例子，如果我们问GPT-3（ChatGPT的基础模型），请跟一个6岁的小孩解释登月工程。找到可能的答案对GPT-3一点都不难，它至少能找到4个答案:a是从万有引力出发解释这个问题；b可以从历史出发，比如苏联卫星上天了，导致美国的危机感，所以启动登月工程；c可以从天文学出发，月亮是地球的一个古老卫星；d可以从人类的美好愿望出发，月亮上有嫦娥有玉兔，我们人类老想去那里。

这个问题到底难在哪？是GPT-3不知道哪个答案更适合给6岁的小孩。

OpenAI就想了一个非常好的办法，就是让人给答案进行排序。在面对6岁小孩时，人的排序就是d\>c\>a=b，即从d开始讲，6岁小孩更容[易接](https://36kr.com/project/2144658078893314)受。当人把反馈给了GPT-3后，它就会把反馈学去了，学会对答案怎么排序，排完序之后的模型，就从原来的GPT-3变成InstructGPT（ChatGPT的初始版本）。GPT-3大概有1750亿训练参数，而InstructGPT只有它1%的大小，即13亿参数。但是这个模型它学完后，你再去问它，给6岁小孩写一首关于青蛙的故事，他就会在开头说once upon a time，类似于儿歌一样的开头。

由此可见，**人的反馈对ChatGPT非常重要，能够让它以人的价值观和理解去学习排序，这也是人类用户感觉到ChatGPT有很高情商的原因。**但这是很多人担心的，ChatGPT能学习到带有带有训练用户价值观的输出，通过排序打分会改变它采用答案的优先级，这也是为什么很多监管部门在关注这个问题的原因。

此外，ChatGPT的多模态协同交互也非常重要。同时，AI与环境的协同演化也很重要。ChatGPT这个人机协同的系统，很难用到非常复杂的需要实时的终端里去。如何在不同的边缘计算资源、通信带宽条件下，有效利用类ChatGPT的能力？这是产业互联网及其生产实践里的一个非常重要的话题。

我们现在也在研究如何让云端的ChatGPT的能力，能够部署到工厂的生产、设计、实践各个环节里进行有效利用，通过终端跟专业用户的交互协同，把人的专业知识学习放到边缘端的模型里，同时又能让云端的ChatGPT根据大量边缘端的进步不断迭代。按照InstructGPT的模式，就变成了原来是云端模型直接跟人交互，现在是云端大模型与边缘小模型交互，这些小模型再去跟人交互，这就是我们团队研究的AI与环境的协同。这也是在学术界，值得我们未来10年去研究的重大课题。

**一个巨大的范式转移**
-------------

ChatGPT的出现是一个里程碑事件，过去二十多年里，为公众所熟知的DeepBlue、IBM Watson和[Alpha](https://36kr.com/project/2144827203667203)Go等AI应用，往往通过与人类竞争制造热点，并以超过人类的效果获得广泛关注，**而ChatGPT第一次提出了人跟AI协同共创，这带来了一个巨大的范式转移。即人工智能的新一轮创新一定会围绕人机的协同共创来展开。**这个路径展开后会带来更大量的应用，进而带来生产力格局的演变。这对人工智能技术企业的影响非常深刻。

另外，从更高层面上来讲，ChatGPT对相关行业影响也非常深刻。

我举一个科研的例子，《Nature》杂志1月5日的封面文章，主要就讨论了过去几十年人类科学的论文越发越多，但突破性的成果越来越少的问题，不光在中国，整个世界都出现了同样的情况。

我认为重要原因之一就是随着科技的大量发展，每个学科都已经非常完善，学科里面开始形成了信息茧房。在一个学科非常小的子领域内，论文就越来越多，而在这个领域里，研究人员要读大量的论文才能覆盖一个很小的领域，所以信息茧房内的信息过载，茧房之间壁垒过高，最终导致一个研究人员要花大量时间去掌握这些知识，那他创造的时间就少了，交叉创新的机会就更少了。

设想如果人工智能系统可以把大量领域里的所有基础内容全部掌握，然后去跟人对话、去交流、可以帮人做各种验证、论证和计算，和启发人，这样最终人就可以有更多时间做最有创造力的突破性工作。

这就是我们讨论的一种新范式。**这种范式一旦成立，意义极其巨大，会形成一种人工智能跟知识发现的新飞轮。**即人工智能做得越强，它的知识、理解、推理等组合能力越强，就越能帮助人类发现更多更好的突破性的科学进展和新知识，包括新药的发现、癌症的治疗、人脑的研究等。

而随着这些新知识的获取，我们就越能帮助世界创造出更好的人工智能，新的人工智能突破又能带来更多知识，形成人工智能-知识的一个正向飞轮。

**AI加速产业创新与应用**
---------------

我认为，人工智能会帮助人类做更好的高质量发展。

因为AI能够助力企业创新，这也是我在产学研结合领域非常关注的事情。我们希望借助人工智能的数据分析、理解推理、计算能力、设计能力，去帮助人更好地洞察市场、洞察消费者、进而设计出创新的产品。也就是生成创意、生成产品、完成设计图纸、生成销售计划等原来需要很多专业人士完成的工作，都可以让AI帮助加快做成，最终让人来做判断，这是生成式人工智能、人机协同带来的全新的创新。

如果这样去考虑的话，有很多产业机会值得关注。因此有很多投资者问我，怎么看人工智能和大模型ChatGPT的未来产业机会？

我的回答就是，去观察一家美国硅谷的VC叫A16Z。这家非常有名[的高科技](https://36kr.com/project/2050874919593856)风险投资机构把整个生成式人工智能AIGC技术分成这么几类：最底层的是计算硬件，如GPUs；再上层的是做云计算平台的，如AWS，以及国内的阿里云、腾讯云；再往上就是作闭源人工智能通用大模型，如GPT-3、ChatGPT等的公司如OpenAI，以及一些开源模型。基于这些模型，上面有做各种应用的公司；特别值得注意的一类就是把底层自有大模型能力和应用融合起来，我们叫端到端的公司。

A16Z的观点是，目前ChatGPT等非常新的前沿技术，具体的可持续的商业模式还不明确。不像底层的计算硬件和云肯定会获利，包括微软等公司；应用层做APP的，因为没有护城河，也难以保证获利。唯一明确就是端到端的公司，如美国的Midjourney，具有非常明确的前景，这家公司现在每年能拿到1亿美元的可持续订阅费。衔远科技按照A16Z对业务模式分类中就属于端到端的应用。

为什么这种模式从长远看更有竞争力？从技术角度来讲，是因为它把基础设施、大模型、应用场景和终端用户形成了一个非常重要的闭环。当公司有了具体的功能让终端用户使用，进而会产生非常多的使用数据，数据反馈后又能帮助提升应用，也能帮助提升基础模型能力，最终模型也会不断去调优迭代越做越好。

此外，大模型也是未来产业发展的重点，但大模型的商业模式值得探讨。因为大模型的成本壁垒非常高，大公司和小企业都有各自的负担。**所以我觉得从端到端做起，慢慢迭代出更大的商业模型，或许是更适合的做法。**

这样又会产生一个疑问，就是把闭源模型加上一个垂直应用打包在一起，是否能取得端到端的商业模式？

ChatGPT现存的一些弱点，让这个问题的答案是明确的否定。目前，ChatGPT就像一个典型的"万金油"，它什么都知道一点，也能非常合乎逻辑地把一些信息整合出来，但很多回答存在无法保证信息准确、量化的问题；第二，对于信息特别是数据自身的关联，它难以建立背后的逻辑；第三，它不能提供独特的洞见，它基本上就是一个更高级的留声机。

一旦垂直领域专业用户使用ChatGPT，他就会发现ChatGPT提供的答案，要么就是专业用户都知道的内容，要么它可能一本正经地信口开河，不能保证它回答的对不对。

因此，衔远科技做了一个垂类的模型，叫ProductGPT，帮助企业做产品创新。它可以帮助垂直领域的企业工作人员做创新，在回答时给出非常全面的分析。因为它有很详实的数据支持，另外它能够按照品牌、品类、特点去展开深度分析，真正帮助到专业人士。

ProductGPT作为垂直领域的协同交互式人工智能，按照我们目前收集的测试，它能够让创新机会翻10倍，上市周期快将近10倍，创新成本大量降低，帮企业带来收入、业务增长和利润。

**ChatGPT对产业、政策、监管等的意义**
------------------------

ChatGPT的多轮生成对话，可能会引发一些新的人工智能治理问题。我总结了三点：

**1.如何从治理的角度对ChatGPT的输出加以标注？**

对人工智能生成的内容中有可能存在彼此矛盾冲突的信息、错误知识、过时知识、谎言、偏见、种族歧视等予以标注，帮助用户谨慎对待。比如，我们需要讨论是否及如何对AI产生的内容增加数字水印，让大家看到时就知道是人工智能生成的而更谨慎对待？

**2.ChatGPT相关的知识产权问题及相关法律问题研究。**

ChatGPT在实际应用场景中必然会引发许多版权问题，其训练过程中使用了海量互联网语料，这种对已有文本数据的模仿也会构成侵权。ChatGPT生成内容的知识产权是归用户，还是归原创内容的所有者，还是归OpenAI？同时，因为使用ChatGPT带来不良后果的责任该由谁来承担，相关的法律问题也亟待研究。

**3.ChatGPT使用范围的界定，其已经对许多行业带来了冲击。**

例1：中学生会借助ChatGPT来完成作业，但由于其生成内容的不可控性，会带来法律、安全、伦理风险，甚至引导学生犯罪。

例2：在学术研究中，如果把思考任务交给自动聊天机器人，也会违反学术伦理规范。

我今年年初在美国计算机协会的会刊ACM Computing Surveys上，发了一篇论文 《可信赖的人工智能：从原则到实践》提出，可信赖的人工智能不是一个孤立的问题，一定要把人工智能的可解释性、抗攻击性放在一起综合考虑，包括ChatGPT现在碰到的问题，都值得在学术上面研究。有关泛化性、可解释性、透明性、可复制性、价值对齐、负责任等问题都是需要去解决的。所以总的来讲，现在人工智能还有很多的工作要做，特别在ChatGPT的大背景下，学术研究、监管和实践是三位一体的，要互相迭代。

本文来自微信公众号 ["中国企业家杂志"（ID：iceo-com-cn）](http://mp.weixin.qq.com/s?__biz=MTI3NTQ1MTY0MQ==&mid=2650576886&idx=1&sn=157726864d442c59da9796636e0ff418&chksm=7c3218604b459176683a25673388c99608afc469360c90db01d63c80905f44fdad99b473a17d#rd)，作者：孔月昕，36氪经授权发布。

[跳转到 Cubox 查看](https://cubox.pro/my/card?id=7032836557832718586)
