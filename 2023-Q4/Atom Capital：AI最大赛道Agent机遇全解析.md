Atom Capital：AI最大赛道Agent机遇全解析
=============================

[mp.weixin.qq.com](https://mp.weixin.qq.com/s/5IDVKooH2hZXUFGnSW9luw)科技最前沿的 Atom Capital


<br />


**写在前面**


Agent无疑是近期AI创投领域最火热的赛道。自3月AutoGPT爆火出圈之后，越来越多Agent初创项目涌现并拿到融资；随着OpenAI DevDay推出其官方Agent框架Assistant API，更是让这个概念进一步"火出圈"。几天前，Bill Gates发表文章表示Agent不仅会改变每个人与电脑互动的方式。它还将颠覆软件行业，引领自输入命令到点击图标以来最大的计算机革命。


Agent一直是我们关注的重点方向之一，在上半年就做了相关投资布局。在与大量创业者交流中，我们发现，围绕Agent大家有非常多奇思妙想的创意，同时也有很多困惑之处，在落地实践中遇到不少挑战。我们近期组织了一次闭门沙龙，邀请AI领域专家和一线Agent创业者深入探讨Agent的落地、挑战及机遇。会上有很多精彩的实践经验和洞察，相信对朋友们会有启发。我们将部分观点整理成文，感谢与会者的精彩分享：段楠（MSRA研究员）、胡一川（来也科技CTO）、周健（澜码科技创始人）、陈龙博（illa Cloud创始人）、苏少炜（法千言创始人）、王磊（人大高瓴人工智能学院博士）、张东晖（前微软Bing亚洲搜索技术负责人、前阿里云产品负责人）和孙锋（微软搜索广告General Manager）。


**01****狂飙的Agent---Agent 2023大事记**


*"如果一篇论文提出了某种不同的训练方法，OpenAI内部会嗤之以鼻，认为都是我们玩剩下的。但是当新的AI Agent论文出来时，我们会十分认真且兴奋地讨论。普通人、创业者和极客在构建AI Agents方面相比OpenAI这样的公司更有优势。*"**

*-- OpenAI联创Andrej Karpathy*

如果说现在还有什么AI领域的"点子"能让OpenAI为之兴奋，那非Agent莫属。从一个学界研究的概念到走入大众视野，Agent只用了短短不到一年时间。如果大模型是未来水电煤一般的基础设施，那么Agent则是未来用户接触、使用AI的方式。我们梳理了今年Agent狂飙突进的重要milestone，从中也可以窥见它的核心发展脉络。

*
  2023.3.16，微软发布Microsoft 365 Copilot，引发业界巨大反响，提示了一种基于LLM的应用开发范式，也即今天形成行业共识的Agent。
*
  2023.4，以AutoGPT为代表的Autonomous Agent 热度快速蹿升，AutoGPT成为GitHub历史上star数增长最快的项目。同期比较受关注的类似项目包括：TaskMatrix.ai，HuggingGPT, AgentGPT, Toolformer, BabyAGI等等。
*
  2023.6，OpenAI 应用研究主管 Lilian Weng 发布博文《LLM Powered Autonomous Agents》进一步推动了agent的热度，Lilian提出**Agent = 大型语言模型+记忆+规划技能+工具使用。**
*
  多Agent框架相继发布，相对于单一Agent框架能够更好地解决复杂问题。目前比较火的多Agent框架包括：Camel(4月发布，3.4k star), MetaGPT(8月发布，29.7k star), AutoGen(9月发布，微软团队，13.6k star)
*
  2023.11.6，OpenAI DevDay，推出其官方Agent开发框架Assistant API，赋能开发者更加高效方便地基于GPT模型进行的Agent开发。


![图片](https://image.cubox.pro/cardImg/2023111522592751983/55200.jpg?imageMogr2/quality/90/ignore-error/1)

**02****Agent Landscape概览**


Agent吸引了大量创业者投身其中，据我们不完全统计，今年下半年在海外拿到知名创投机构投资的Agent项目已超过20家。在此我们做个基本梳理，方便大家了解目前市场上的整体情况：

从创投行业角度，当下LLM based Agent领域初创公司可大致分为两类：

**中间层infra**

提供实用可复用的Agent框架，降低开发Agent 的复杂度，并为Agent的合作提供机制设计。该类项目主要从模块化、适配性、协作等几方面进行创新。其中拿到知名机构投资的代表项目包括：AutoGPT、Imbue、Voiceflow、Fixie AI、Reworked、Cognosys、Induced ai等。


**Vertical Agent**


深入某个垂直领域，理解该领域专家的工作流，运用Agent 思路设计Copilot产品，用户介入使 Agent思路更为可控。其中拿到知名机构投资的代表项目包括：Dropzone（安全领域）、Middleware（大模型可观察性领域）、Parcha（Fintech领域）、Luda（游戏领域）、Outbound AI（医疗领域）、Fine（软件开发领域）。

从Agent的互动/工作模式角度，复旦大学自然语言处理团队（FudanNLP）在其 LLM-based Agents 综述论文（https://arxiv.org/pdf/2309.07864.pdf）中，将Agent分成了三类：**单一Agent, 多Agent以及人与Agent交互（按交互方式又分为指导-执行模式和平等合作模式）**。如下图所示：

![图片](https://image.cubox.pro/cardImg/2023111522592790688/80979.jpg?imageMogr2/quality/90/ignore-error/1)


![图片](https://image.cubox.pro/cardImg/2023111522592711808/42001.jpg?imageMogr2/quality/90/ignore-error/1)

**03****Agent落地：场景和挑战**


本次沙龙参与者既有学界资深的AI研究员，也有富有实战经验的一线Agent创业者。对于围绕Agent大家关心的若干问题，我们进行了深入讨论，以下是本次讨论的一些精彩观点：

**Agent适合在哪些场景落地？**

创业者们已经尝试了各种落地场景，总结下来，以下几点更契合Agent的落地。

**做到比人（普通员工）** **好**

客户不一定要求Agent达到专家水平，很多场合只要比普通员工好就够了。Agent PK的，实际上是月薪几千元的员工。比如，公司IT部门要响应业务人员的各种需求（如临时报表）。如果提供对话式UI，通过几轮对话让业务人员说明白需求，Agent来自动生成，做到这个，客户已经愿意买单了。这样IT团队可以从琐碎中解脱出来，做更重要的事。

**Text to SQL**

Text to SQL 在企业落地上有很多案例，以上例子本质上就是Text to SQL, 只不过多了很多新的数据来源：比如从商业化中最值钱的文档（合同、财报、简历、招投标书等）中提取数据。把这些数据连同专家知识一起灌给大模型，把信息抽出来，通过Text to SQL来回答问题，这件事已经很值钱了，可复制性也很强。

**写代码**

帮程序员写代码这个场景毋庸多言。一个有趣的发现，是大模型些代码大部分时间做的是写正则表达式。正则表达式是个没多少人会写、但是很好用的东西。程序员调试，之前在这里经常花很多时间，用了大模型之后发现很快就能解决。这带给我们一个启发：有很多人类不擅长但AI很擅长的细分领域，是最适合Agent去落地探索的。

**解决头部问题是落地关键**

我们看到在Agent领域有很多漂亮的Demo, 但能否将企业转化成为真正的长期付费者，一个核心是当这个工具真的进入企业后，员工是不是可以真正把它用起来解决问题。Agent肯定会有不好用的地方，关键是要先能把大部分员工的头部问题解决掉。做到这个，再出现一些小众长尾问题，能让大部分用户觉得，这是人的问题而不是AI的问题，就好办了（这种情况下，人会调整自己使用Agent的方式，比如更改询问方式等等，通过人向AI靠拢的方式解决的一部分长尾问题）。

****为什么**Agent****落地这么难?**

目前最让开发者头疼的一个问题，是虽然很多Agent demo看起来能解各种问题，等真正应用在实践中，特别是2B业务流程中，好像总是不工作。这也是为什么Agent被很多用户戏称为"玩具"------Agent想要真正落地非常难，但只有解决了这个问题才能开启商业化的道路。这可能是Agent领域最关键的问题之一，围绕Agent为何落地困难我们进行了深入探讨，总结了实践中碰到的挑战以及背后更深层的原因。

从实践层面，影响目前Agent落地的问题主要有如下两方面：  

**API质量差，没有形成生态**

Agent在2B领域落地，有些类似ChatGPT Plugin搬到2B领域。但ChatGPT Plugin发布之后，实际落地的情况与预期有很大差距，我们分析背后原因在于两个：一是背后的API不够丰富、质量差（比如描述不清晰），二是试图用一个模型解决所有的垂直问题（大模型对于垂直场景的理解未必足够）。第一个问题在国内尤其严重。企业服务API生态在欧美非常成熟和开放，中国还很不完善，开发者很难赚到钱。这些让Agent很难真正在生产环境落地。

**开放场景 vs 封闭场景**

Agent的落地效果与场景的封闭程度也很相关。一个典型的对比是Agent在法律助手 vs 出行预订场景。前者场景不够封闭，经常有新知识（如新的法律法规、新的判例）出现，API也不够完善。要做成真正的律师"助手"还有比较大的挑战，比较现实的是做成一个帮助律师整理文档、搜索案例的提效工具。而后者场景封闭（可以穷举）、API丰富（机票、酒店等都有明确的API），在落地中的效果要好很多。最理想的落地情况，是有大量垂直领域数据（给到大模型做预训练）、场景封闭、问题基本可穷举。

而从更深层的角度剖析，我们认为Agent之所以落地困难。背后的核心是大模型目前还缺乏解决相关应用领域的"世界模型"。  


![图片](https://image.cubox.pro/cardImg/2023111522592838752/54533.jpg?imageMogr2/quality/90/ignore-error/1)

**04****Agent成功的关键 ------"** **世界模型** **"**

上文所谓应用领域的世界模型，是指Agent落地到具体应用场景，要理解当下任务并预测未来情景，这需要超越简单的文本学习，深入获取领域知识、领域相关的私有数据以及相关任务的"过程数据"（即领域专家是如何分解任务、产生结果的）。大模型在训练过程中，尤其缺乏"过程数据"，这让世界模型的建立变得困难。

****为什么大模型训练为何会缺乏"过程数据"？****

**1）训练语料问题。** 大模型学习主要的语料来源是网络文字。但目前语料中，绝大多数都是关于"What"的，关于"How"的很少。尤其在2B业务领域，绝大多数的成功经验和失败教训都不大可能被公开分享出来。前者多为创造价值的商业机密，而后者则很少会被主动分享，即使公开，也有很多美化及偏离事实的可能性，这可能会带来大模型的错误归因。

**2）即使在"私有数据"中，关于过程的数据也依然很少。** 大量的所谓"经验"是存在在相应岗位专家的大脑里的，并未以任何文字的形式被记录下来。

举个例子。在招聘领域，通常企业的用人标准会有"工作稳定"一项，但针对不同的岗位、不同的行业这个"工作稳定"所对应的标准是完全不一样的。这些"知识"是人类HR/猎头脑海中的经验，针对岗位、公司的不同，自然就能把"工作稳定"对应到不同的标准，有时候甚至只是一个行业的"共识"，并没有什么成文规定。但是让大模型来做这件事，就需要详细地把各个行业、岗位、工种、对应的"工作稳定"的标准写下来告诉它（大模型在训练语料中几乎很难获得这种很少出现在文字/语料中的专业"知识"），否则大模型缺失了这部分的"知识"，做"工作稳定"这一标准的筛选准确率自然就低，而千千万万个这样的"知识点"就构成了一个招聘领域的"世界模型"。

**3）缺乏大模型执行任务过程的"标注数据"，无法形成反馈-优化闭环。** 目前大模型基于网络语料的学习，是每采取一个行动，都对应明确的Ground Truth. 大模型基于用户对问题的反馈来不断迭代升级。但Agent的问题在于，绝大多数agent执行到任务的最后一步，才是对用户需求目标的达成，因而只有在最后那一步才有标注结果。对于其解决问题的中间过程，很多时候Agent得不到及时的反馈------做的是否正确、是否有更优的做法等等，这也让Agent"自我进化"变得缓慢。

****看好掌握领域"世界模型"的Vertical Agent****

我们判断，各领域"世界模型"的建立是AI走向落地的重要一环，也是AI向AGI发展的关键环节。现阶段"世界模型"的缺乏，是大模型的"缺陷"也给大量做Vertical Agent的公司带来了很大的机遇：构建垂直领域的"世界模型"需要相关公司做大量的工作收集、整理领域知识和私有数据、理解具体业务的工作流等等，是一个相当复杂的系统工程。尤其在法律、医疗、金融等数据庞杂、专业性极高的领域。一旦有Vertical Agent的公司能够建立、掌握这些垂直行业的"世界模型"，也就拥有了在这个不确定时代极强的竞争壁垒。我们非常看好这类创业公司在未来的前景。


![图片](https://image.cubox.pro/cardImg/2023111522592875714/13508.jpg?imageMogr2/quality/90/ignore-error/1)

**05****Multi-Agent：为何它的效果明显更好？**

最近半年Agent领域一个明显的趋势是"Multi-Agent"框架的流行。很多开发者发现，当事先给Agent设定不同的角色（如产品经理、程序员、UI/UE等等），再让这些Agents一起"协作"完成一个任务时，要比AutoGPT这种单一Agent框架效果好很多，任务完成度更高。相比单一Agent，Multi-Agent除了给大模型设定了角色，好像也没有提供更多的增量信息。为什么这个框架会明显的有效呢？


我们认为有如下几点原因：

****角色扮演有引导性，更容易让它聚焦到相关的概率区间****

大模型本质是概率模型，每次输出都不一样。它在训练过程接受了丰富的语料，面对一个问题时，大模型有很多不同的角度和观点，但它自己并不知道应该找哪一个切入。这时如果用户给它一个角色，让它聚焦到一个身份、一种观点上去，它更容易进入到一个与问题相关性更高的概率空间，把其中的专业内容挖掘出来。给大模型一个身份看似没有增量信息，其实一个"角色"背后已经隐含了很多与角色相关的信息。

****让大模型做更多的"算力消耗"，System1 vs System2****

OpenAI联创Andrej曾经分享过，他认为Prompt Engineering中思维链（Chain of Thought）之所以有用，就是类似"Let's think step by step"这样的Prompt，让大模型在输出的时候消耗了更多的算力。这点跟人脑类似，人脑在解一个复杂问题时会消耗更多能量。而Multi-Agent正是这样一套能让大模型输出更多、从而消耗更多算力的机制。大模型其实跟人脑的System1类似，特点是不论用户给它的问题难度如何，它的思考时间（对应背后的计算量）是一样的。而目前在Prompt层所做的思维链、Multi-Agent等等工作，都为了让大模型从System1向System2发展，越复杂的问题思考得越久。通过Multi-Agent框架，可以让它消耗更多的算力、做更多思维层次的计算和思考，更有可能更好地解决复杂任务。

这又引申出了许多创业者遇到的一个问题：**并非所有问题都需要System2的能力，如何区分面对的问题需要System 1还是System2解决呢？**如果都用System1的方式解决，那么复杂问题得不到很好的解决；如果都用System2的方式解决，那么又会"杀鸡用牛刀"，既浪费算力、又拉长了反馈时间。最好的方式是能针对问题做好分流。这意味着Agent需要对海量的新问题做实时判断，该用哪种方式解决，而这是绝大多数Agent很难做到的。目前有些创业者在探索先用大模型对问题做一遍意图识别（分类器），再分流到不同的解决方式中去做具体执行。但在很多垂直领域（如法律等），把这个"分类器"做准确的难度依然很大。

****结合多个大模型的最强能力****

前面两个角度，是如何通过Multi-Agent激发大模型发挥能力，背后对应的是一个能力强大的单一大模型。还存在另一种视角，就是Multi-Agent用来结合多个大模型的特色能力。虽然目前OpenAI在大模型领域"一骑绝尘"，我们也观察到其他头部大模型更注重在一些独特能力上的训练（比如更强调与人类的共情能力、更加注重alignment等）。在未来，当这些各有所长的大模型都进入生产，Multi-Agent框架会很方便地融合各家大模型的优势"为我所用"。

![图片](https://image.cubox.pro/cardImg/2023111522592811545/41554.jpg?imageMogr2/quality/90/ignore-error/1)

**06****多模态：对比大语言模型有哪些提升？**

大语言模型正在向多模态大模型发展，对比大语言模型，它带来的能力提升有哪些，有什么深刻的变化？对创业者又多了哪些机遇？

****从一个简单问题类比说起****

我们先从讨论一个简单的问题开始：聋子和瞎子，一个没有听觉，一个没有视觉，哪个智力水平高？实际上瞎子的智力水平更高。这背后的原因是语言比视觉对人脑来说更加重要。视觉给我们的反馈，不如语言的反馈那么复杂。这是个抽象程度的问题，语言比视觉抽象程度更高，人和动物的区别是人有语言。所以，目前视觉等多模态模型，对于模型能力并没有一个质的提升。

具体解释一下，目前的多模态模型，是通过某种connection把视觉和文字两个模态的数据对齐 --先训练单模态，再通过对齐，去做成多模态。它还没有真正从预训练的时候，就把文字、视觉绑在一起从头训练，因为现阶段跨模态对齐的数据还是太少了。大家认为可行的思路还是先训练单模态然后再做对齐。除了语言模型，目前其他模态的encoder能力和量级相比都差很远（比语言模型小1-2个数量级）。所以现在这条路效率最高，一下能通过语言模态赋予其他模态更高级的能力**。这种多个模态对齐的多模态大模型，在能力上不会有突破式的飞跃，因为核心能力已经在语言模型里面了。**

****多模态带来的好处****

**视觉比语言有更多的信息。** 目前大模型都是基于Transformer架构，这个架构本身跟语言关系不大，它只是在处理token之间的关系，最后再把这些token折换成语言。从这个意义上来说，不同模态的"语料"之间并没有质的区别。因此，考虑多模态的影响，要考虑视觉中究竟包含了多少语言里没有的信息。比如，视频中有很多关于现实世界的"common sense"（如空间位置、重力、光影等等），在语言中是缺失的，这部分信息的补足对于建立对真实的"世界模型"是很有帮助的。这对于后续大模型在自动驾驶、机器人等需要与真实世界互动的场景中落地有很大意义。比如，聋子和瞎子能干什么不同的事情？瞎子是不能开车的。如果GPT有了视力，是可以开车的，无人驾驶可以靠GPT来理解周围的环境。

**多模态极大增强了交互的输入输出带宽。** 许多用文字很难描述、或者需要非常长、复杂的文档才能描述的关系、内容，可以通过画图的形式给到大模型，输出也是如此。这让人机交互的输入输出带宽一下大了很多倍，带来的直接效果是大模型处理同样任务的效果更好、效率更高，也一定程度上解决了token限制的问题。Context输入一下子扩大了很多。比如，可以给大模型几万行代码对应的架构图，它可以很快整理出模块之间的关系，这是没有多模态之前无法达到的。

![图片](https://image.cubox.pro/cardImg/2023111522592866481/83149.jpg?imageMogr2/quality/90/ignore-error/1)

**07****对Agent未来的几个预判**

最后分享几个我们对Agent未来发展的预判，与大家探讨：  

**AI Native工作流**

Agent在2B领域落地，目前是按照人类工作的流程切分的，没有考虑到机器，也没有"人机协作"的概念。只是沿用过去的流程把机器加入很可能已经不是最优方式------既无法发挥机器的最大效率，人类员工也不适应。因而做2B场景的Agent，需要重新思考人机协同的工作模式下，什么样的工作流程是最优的，再自上而下地重塑工作流。AI native的工作流应当是什么样？这是个开放性问题，并没有明确的答案，但这个问题可能会定义下一代的企业级软件，是值得现阶段的初创公司去深入思考和探索的重点问题。

**真正的多模态**

未来可以有一开始就把多种模态的语料一起训练的多模态大模型。或者，等视觉模态encoder的能力和量级可以跟现在的大语言模型等量齐观，用它来辅助做决策，或者两个大模型共同做决策，可能会爆发很大的潜力，带来突破式发展。

**Agent的自我进化**

随着AI能力的逐步增强，未来Agent将如何演化？也许，它们可以实现"自我进化"。比如，自己生产出新的Agent，或者设计出适合Agent协作的全新的组织结构来完成复杂的任务，就如同人类发展出了适应人类社会的复杂协作模式和分工体系。这是一个很值得思考的前沿方向，背后是Agent之间的通讯及协作模式。目前这个方向的研究还非常的少，我们觉得是很值得探索的一个领域。


***About Atom Capital***


*Atom Capital是一支由连续创业者和投资人成立的新锐风险投资基金，专注于AI、大数据和云原生领域的早期投资，聚焦颠覆式创新机遇，发掘、孵化和陪伴优秀的科技创业者成长。*


[跳转到 Cubox 查看](https://cubox.pro/my/card?id=7124481552024604128)
