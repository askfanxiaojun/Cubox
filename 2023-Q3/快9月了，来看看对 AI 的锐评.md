快9月了，来看看对 AI 的锐评
================

[mp.weixin.qq.com](https://mp.weixin.qq.com/s/oqJOaJJpu6eZa7sie0kRVw)Cherry 车厘子电波

### **![图片](https://image.cubox.pro/cardImg/2023090420250864613/81272.jpg?imageMogr2/quality/90/ignore-error/1)**

### **前言**

别人家研究员的相关研究做的都不太好，于是亲自写了一份给内部看。想了想决定把其中攻击性太强的部分删掉、对外发一遍。

新行业噪音大，多动脑、敢于下判断总是没错的。对于判断题，盲猜的正确率是50%，而连续猜错三次的概率是12.5%，哪怕是扔硬币级别的下判断，也是有意义的。下判断并不可怕，判断准确率低于扔硬币才是最可怕的。

本文下判断的数据依据主要来自Dylan Patel的爆料，如果爆料数据不属实，跟算术相关的部分肯定会出错。请多包涵。

### **大模型和发射火箭**

大模型（的预训练）目前已经转化成了发射火箭问题，只要烧的起、方向对，谁都能做。

但发射火箭也不是那么简单的。比如中国的资本市场，越发不活跃，几乎没有初创公司能够承受一次炼丹的失败。投资人对大模型训练的难度是低估的，而对发射真火箭（蓝箭）的难度是高估的。同样是6000万美元的成本，投资人会觉得火箭升空失败还可以有第二次机会，而训练大模型失败则被认为是浪费资金。

但是，GPT-4在OpenAI的脚手架效率（30%）上，仍然消耗了6000万美元。这是一个【性能=效率×成本】的问题，而性能是道墙，如果其他的初创公司不能实现大于30%×6000万=1800万美元的性能效果，则用户不如直接用GPT-4。

在中国，融资轮次大部分都在500万人民币\~2000万人民币这个区间，能到1亿的是凤毛麟角。也就是说，即使是最大融资额的公司，其弹药量也只足够支持一次发射。

![图片](https://image.cubox.pro/cardImg/2023090420250854862/33115.jpg?imageMogr2/quality/90/ignore-error/1)

从这个角度来说，发射火箭是更好做的，因为目前大部分火箭都是运载火箭，带着卫星上天，而单次负载量有限，所以小的火箭公司可以接别人来不及发射的卫星单。

大模型则不同，大模型的横向扩展的边际成本只有算力成本，而算力成本可以是弹性扩张的，也就意味着对于大模型公司来说，每一单的利润都是白捡的利润，几乎不用付出额外成本，承接能力非常大。对于新成立的、质量差的大模型公司来说，很难接到溢出的需求。

也就是说，除非训练成本大幅度下降，否则即使知道了GPT-4的全部架构，中国公司也几乎做不出大模型。

即使是国外的公司，大模型部门的费用开支也受到组织架构的严格约束，例如google的Bard，虽然燃烧了大量费用，最后却做出了一个稍微强化过的搜索引擎，不可谓不浪费。

### **定制化不是出路**

在硬件行业，一种常见的现象是通过定制化需求来实现早期的利润，再通过早期利润实现技术突破（或者追平）。然而在大模型方向，赢家通吃是一种可预见的情况。

![图片](https://image.cubox.pro/cardImg/2023090420250812948/83416.jpg?imageMogr2/quality/90/ignore-error/1)

之所以说定制化不是出路，原因是绝大多数微调后的模型追不上GPT-4，即使追上了，而这种情况下，直接使用GPT-4泛化的成本更低、人员需求更少、运气需求更少、数据需求更少。

只要GPT-4和其他模型的断档级性能差距还存在，定制化就不能成为大模型公司的出路。

因此，寄希望于通过定制化积累利润、实现技术突破的路线，基本都是错的。

比起积累利润，还不如等着老黄哪天大发慈悲把显卡价格降下来。

当然国内做还有合规问题，这个另讲。

### **简单的算术问题**

（以下计算完全靠直觉，我又没做过预训练；出错了请去后台直接骂我，谢谢）

根据Dylan Patel爆料的数据，可以进行一些简单的算数。

GPT-4的训练基于N卡的A系列，训练效率30%，训练时间大约2个月，成本约6000万，总参数量为【1.7万亿=1100亿×16个专家模型】，实际处理单个问题的参数在2800亿左右。

也就是说，有几个关键参数，会导致大模型训练的格局发生变化。

* **训练效率**：从30%提高到60%可以直接缩短一倍时间

* **算力密集度提高**：从A系列换成H系列后，算力密集度提高，很多架构上影响效率的问题都可以解决

* **算力成本下降**：老黄打折

* **参数效率提高**：LLaMa的参数效率是GPT3的10倍，也就是用10%的参数实现了差不多的效果，如果参数效率还能进一步提高，也许不需要1100亿的专家模型参数就能实现很好的效果；考虑到GPT-4处理单个问题的参数只有2800亿，总参数量很可能还有3\~4倍级别的提高空间

*
  **transformer加速的更新**：老黄提供的transformer加速效果不好，可能还有很多提高空间

综上所述，从零训练出GPT-4级别性能的模型的成本可能有10\~20倍的优化空间，也就是压缩到300万美元\~600万美元，这个成本对于初创公司和大公司费控而言，都是更容易接受的。

而这个变化，可能需要2年左右的时间来完成。

目前，语言大模型的技术仍然基于transformer的思想，根本架构上并没有变化，只是炼丹加参数的大力出奇迹思路仍未穷尽。GPT-4的训练在算力限制很大的基础上进行，且训练时间不够长。

如果参数是随训练时间线性增长的，目前单个模型（不考虑混合专家模型）的理论极限参数量可能在6000亿左右，总量为10万亿。按照硅谷的风险偏好风格，这个参数量大概率会在一年内达到，无关乎性能。美国对于"能做，但要花一点点钱"的事情是无条件支持的。

![图片](https://image.cubox.pro/cardImg/2023090420250945263/71510.jpg?imageMogr2/quality/90/ignore-error/1)

然而在达到10万亿参数后，LLM是否还能使用增加参数的思路大力出奇迹，就是一件完全未知的事情了。

预测炼丹很难，但预测企业战略节奏很容易。总参数10万亿的模型对于绝大多数企业，无论是Google/MS/APPL这种巨无霸，还是小一点的OpenAI，都是一个里程碑级别的终点，是可以停一停、做些技术探索的位置。

当然，如果老天爷赏脸，让模型性能一直跟着参数上升而线性乃至指数上升，更大规模的模型仍然会被训练出来。但这需要很多的时间，因为人类的工艺成长速度不够快。企业/资本对于风险的偏好可以折算成一个"忍受时间"，如果整个忍受时间都在剧烈燃烧费用，则很难超过6个月。

因此，在5年内的极端极限很可能是20万亿\~50万亿，超过这个数量级的概率极低，可以说约等于没有。

------毕竟这不是炼丹问题，而是工艺问题。工艺追不上、全靠风险偏好来补，是不长远的。

### **多模态**

目前多模态模型做的都很抽象。

（此处略去27字对某几家LLM的锐评），GPT-4是在LLM基座上用了图像token做微调，GPT-4的多模态始终不开放可能也是效果不好的原因。

GPT-5大概率是原生支持多模态的，也就是需要重新设计结构、重新训练。但市面上能进行图片生成的模型都不大，跟LLM不在一个吨位上。所以，原生多模态的模型具体是什么样，属于完全未知的问题，大概率需要一年左右的时间才能有好的解决方案。

按照{简单算术题}部分的推理，一年内参数还有5\~10倍的成长空间，大概率足够放入多模态的部分。

多模态对单一图像模型是毁灭性打击。往后单一图像模型公司可能会转型成做定制化服务的小公司，就像Runway（排版cherry：你管15亿美元估值叫小公司？）。

站位很重要。

### **站在一年后回看**

炼丹不需要那么久，且大公司都在买显卡。一个非常显而易见的事情是，一年后，**大型公司都会有能力训练GPT-4级别的模型**。不过到底要不要训练，就是另一个问题了。

GPT-4不是重点，在现在的工艺、架构、资金偏好上，参数成长到10万亿是一个确定性事件，未来一年很可能会出现性能远超GPT-4的新模型。本着"有原神玩原神"的定理，即使别的公司都能训练出GPT-4了，如果性能更高的GPT-5出现，市面上流行的大概率也是新模型。

做AI应用的团队，最好对齐性能最高的模型。只要第一个火箭上天了，第二个就只需要看资金什么时候跟上，在模型性能提高速度很快的当下，选择停留并不是个好选择。现在有些做AI应用的团队的代码已经和LLaMa2耦合在一起了，如果GPT再来个大版本更新，这些团队会很吃亏的。

直接投大模型公司，不能只看公司能不能训练出来，还要看公司训练出来的模型有没有人用。如果模型没人用，公司只能自己做产品再商业化，其站位就和AI应用团队一模一样了，没什么优势可言。

关于大模型公司的组织架构异化的问题，需要详细讲讲。

### **大模型公司的组织结构异化风险**

由于大模型的二八效应，第二个第三个第四个发射火箭的公司即使能成功，其性能往往也不占优势。因此，除了最头部的AI公司外，后面的大模型公司都要经历长期的疼痛：烧费用，没人用，进而导致缺数据、掉性能。

为了确保公司有商业化产品投入使用，以及能得到商业化产品带来的使用反馈，这些公司可能选择自己做产品，或者把自己的产品向应用层方向做耦合。比如，（此处略去20字对国内多家头部互联网公司的锐评），Google的Bard更是怎么用都像Google。

之前有人质疑OpenAI到底是做API还是做产品。其实对OpenAI这种小型组织架构来说，产品的战略优先级不应该排太高。只要API性能足够领先，市场份额就不愁。而30\~100人的小团队如果分流出大量人马去做产品落地或者应用耦合，会导致公司内"做研发的没营收，有营收的没研发"。这种矛盾会削弱研发团队的稳定性，从而在技术能力上逐渐落后。

因此，我们应该理性看待大模型公司侵入应用层的能力。赢家通吃对应用层而言是不太可能的。

**如果是大型公司，如Google/MS/APPL**

优点

* 整合功能很快，产品部门只要批准就可以上功能

* 对费用耐受性好

* 内部采用率高


缺点

* 纯研发部门的经费和KPI不受待见，性能很可能始终落后半个世代

*
  功能整合快不代表准，最需要整合的功能往往是敏感功能，审批很慢


**如果是小型公司，如OpenAI**

优点

* 对技术理解透彻

* 组织架构能够容忍纯研发的费控和KPI


缺点

*
  组织架构不适合做自有应用，太专注于应用层则技术会落后

### **应用层的生命线**

应用层需要使用大模型的服务，而大模型的服务性能不断提高。这种提高不是"速度"等单一维度的改善，而是输出质量、输出长度、输出控制性等全方面的改变。每一次技术的显著升级都会导致已有应用层产品的技术落后，而当其进行适配和升级时，有可能出现新的竞品。我们将这种现象称为应用层产品的"生命线"。

例如：

* 当ChatGPT支持文件上传后，ChatPDF就死了

* 当Office365支持Copilot后，（略去两个公司）就离死不远了

*
  当ChatGPT(GPT3.5)出现后，（略去一个MKT公司）就离死不远了


还有一些更隐晦的表现：

* 当OpenAI发布function calling后，**langchain** （这个不略去了，直接骂，而且字体加粗）的伪function calling就显得性能极差

* 当OpenAI淘汰Completion而偏爱Chat后，所有基于Completion的应用层/开发工具都要重写一遍

*
  当GPT-4支持多模态后，（略去对某图像类AI公司的辱骂）

如果产品的选取方向不太好，生命线普遍只有3个月左右。

如果产品做了很深的耦合来提高性能，生命线大约6个月，例如（略去三个公司）。

如果产品的方向选取非常准确，生命线则很长，例如hugging face/civitai。

需要注意，平台类产品的生命周期并不一定长，例如prompt商店，早就死透了。本质问题是选的准不准，跟平台关系不大。

当生命线到尽头，换技术底层算是比较好的结局，更麻烦的情况是需求直接被抢走了，重做产品等于重做公司。

一般来说，选出超长生命线是可遇不可求（炼丹的人也不知道自己能炼出什么来），选出6个月生命线是较好的水平，而大量选出3个月生命线则是缺乏产品和战略层面的考虑。

### **短期项目的意义**

上文已经说过，大多数产品的生命线都在3/6/12个月，少数产品生命线很长。

有一种言论是觉得现在投应用层太早，短期项目没意义，而且短期项目没价值。（略去一家国内知名投资机构的创始人）就说过 (完形填空) 不创造价值。

我个人不太赞同这种言论。

举个例子，美团在组织架构、战略、技术能力上普遍被认为是比腾讯强的一家公司，而腾讯市值是美团的4倍。腾讯的主力产品是微信，美团的主力产品是美团外卖，从创造价值的角度来说，通讯是大部分公司都能做的事情，而外卖不是。

### **眼，手，脑：在不确定性中寻找确定性**


大模型的结构可以分成三个部分：

* 获取信息（眼）

* 处理信息（脑）

* 进行动作（手）

目前，绝大部分LLM都在构成"脑"的部分，而"眼"和"手"则属于应用层。

GPT-4拥有多模态输入图像的能力，但图像从何而来，实际也是"眼"要解决的问题。

从行业结构上来看，虽然"脑"的部分技术迭代很快，但三段式的结构在可预见的未来不会发生显著改变。因此，一种以不变应万变的分析方法是从三段式结构入手，去研究行业中"三段式"的需求情况。

例如，在AutoGPT/BagyAGI/ReACT中，模型耦合了爬虫，从而能够主动获取网页上的信息。虽然其爬取效果实在令人难以接受（后期：其实是烂透了）。

还有一个不太典型的例子，具身智能。这个方向有一些炒作热度的意味，但仍然值得讨论（后期：我觉得烂透了）。具身智能认为要把大模型放进机器人里，而机器人对周围环境的感知，也属于"眼"的一部分。

理解"手"则是从权利的角度理解。

例如，对于一家公司的员工而言，"手"就是在工作群发消息、在数据库查数据等权利。那么，将这些权利接入模型，使模型能够像员工一样控制权利，也可以被理解为"手"。

因此，假设我们希望用大模型来辅助生活，最重要的部分应该就是"手"，即模型被允许做什么、模型该怎么进行对应的操作。在"外卖"这个狭窄场景里，健身的人不希望模型为自己推荐炸鸡，而职场员工则希望模型帮自己自动选出想吃、喜欢吃的东西。对于AI权利的管理，在未来会是一个很大的议题。

实际上，目前对于一些场景，AI的"脑"的性能已经有些溢出，而眼和手的不健全限制了AI投入到应用层的进度。

### **什么是护城河**

很难对这个问题的答案下判断，因此，我罗列了一些QA，希望能有启发。

**Q**：是算力吗？

**A**：现在是，以后不是。算力的成长受限于工艺，而消耗时间对参数量的提升作用是线性的。即使提升了参数量，也不代表模型性能就会提高。"十年磨一剑"是不靠谱的，如果所有模型都要在半年内完成训练，那么模型的瓶颈就是一个"参数硬顶"。就算算力足够，也不能越过去，反之亦然。

**Q**：是用户吗？

**A**：也许是，但大概率不是。Jasper那么多用户，还是被ChatGPT抢走了。当需求的解决方案存在次世代版本时，要求用户停留在老版本是不可能的。至少现在，用户不是护城河。

**Q**：是性能吗？

**A** ：是，也不完全是。GPT-4对GPT3.5的性能是碾压式提高，所以能成为壁垒。但是SDXL对SD1.5的优势不多，MJ对SD1.5的优势也不是特别多（此判断有待商榷）。因此，如果是断崖式提升，确实能成为壁垒。但如果只提高了10%，很难认为是壁垒。

**Q**：是微调吗？

**A**：肯定不是。微调不改变性能，只改善控制。与其说微调能成为壁垒，还不如认为微调的"部署平台"能成为壁垒，这东西才是真的麻烦。所以我看好hugging face。

**Q**：是数据吗？

**A**：可能是。ChatGPT为OpenAI积累了大量可用数据。但从1万亿参数提高到10万亿参数所需要的数据可能也不是这些。与其说"积累的数据"是壁垒，不如说"如何积累数据"才是壁垒，这个问题就太广泛了。

**Q**：是口碑吗？

**A**：可以是。我还挺喜欢文心的。

**Q**：是生态吗？

**A**：不确定。SD1.5的生态确实爽，但LLM的生态做的都很烂。我们把LLM生态扫了一遍，langchain/guidance/vector store全看了，最后选型选了一堆old school，然后不用框架进行开发。我觉得，如果整个行业都在忙着发射火箭，大概率没心思顾及螺丝供应商的死活。

（全文完）  

[跳转到 Cubox 查看](https://cubox.pro/my/card?id=7098350854956123953)
