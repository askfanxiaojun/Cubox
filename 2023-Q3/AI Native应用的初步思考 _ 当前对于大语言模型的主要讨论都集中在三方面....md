AI Native应用的初步思考 \| 当前对于大语言模型的主要讨论都集中在三方面：
==========================================

[www.zhihu.com](https://www.zhihu.com/pin/1621509783713943552?utm_id=0)字节天地大观，志存高远

AI Native应用的初步思考 \| 当前对于大语言模型的主要讨论都集中在三方面：  
1. 大模型技术原理，如何训练构建大模型。  
2. 通过ChatGPT这类产品来持续探索模型的能力和各种错误案例。  
3. 如何利用基于大模型的新产品来提升工作学习效率。

不过对于应用开发者来说，有一些比较重要的思维认知更新值得关注：  
1. 从过往的单一任务分别建模的思维方式，转变成了现在的通用模型加上prompting的方式。由于涌现现象的存在，fine tune或者领域专有模型变得有些"过时"了，更多的是结合外部知识索引形成context的方式来利用通用模型去完成领域任务。  
2. 思维的主要载体形式是语言，因此现在很多大模型都有了"思维链"的能力，可以自我形成计划，使用工具来完成复杂任务，有着很大的想象空间。对于开发者来说，如何提供更好的思维过程示范，拆解任务步骤，对每一步的情境和需求做详细的说明等，都是激活这种模型能力的重要手段。  
3. 未来系统都需要去拥抱自然语言接口，形成一系列最佳实践，使得可以更好地被LLM这样的智能agent来进行交互调用。这会逐渐形成一个AI native app的生态，而不是说仅仅满足于跟人聊天交互。

应用大模型API如何打造壁垒？  
- 大模型是否可以类比为早年的浏览器，手机操作系统。最终直接开发大模型的厂商应该是少数，绝大多数生态都是基于之上的app。反面观点：大模型解锁了"智力"分发，相比浏览器这类，提供的价值深度更大。  
- Prompt本身很难形成壁垒，例子：GPT-4迭代发布后，GPT-3.5里很多复杂的prompt可能不需要了。  
- 在ChatGPT发布后，Jasper的营收仍然保持了每月double digits的增长，这里本质的"壁垒"还是在真正了解了用户问题，而不是模型能力有多强。Jasper的创始人都不是AI技术背景。OpenAI，微软不太可能做过于垂直的场景，应用生态的机会很大。  
- 另一方面来说，以往"数据飞轮"的壁垒效应可能减弱了，因为当前的大模型几乎把互联网上所有的信息都看过了，而且有大量的企业在调用他们的API，他们的数据丰富程度可能远超一般创业公司。要更多思考用户协作的网络效应，以及垂直场景工作流的打通。  
- 题外话，OpenAI大模型本身的壁垒，也不仅仅是模型技术，要更注意应用/开发者生态。这点跟手机操作系统，云平台等逻辑类似。

<br />

[跳转到 Cubox 查看](https://cubox.pro/my/card?id=7081683335432375966)
