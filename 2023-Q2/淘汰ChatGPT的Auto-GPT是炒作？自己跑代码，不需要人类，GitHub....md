淘汰ChatGPT的Auto-GPT是炒作？自己跑代码，不需要人类，GitHub已破5万星
=============================================

[mp.weixin.qq.com](https://mp.weixin.qq.com/s/L0xsYtoxyK1x9iP27-sOQQ)新智元 新智元

### ![图片](https://image.cubox.pro/article/2023041417333174120/29883.jpg)

### *** ** * ** ***
**新智元报道**


编辑：编辑部

##### **【新智元导读】** Auto-GPT究竟是一个开创性的项目，还是一个被过度炒作的AI实验？这篇文章为我们揭开了喧嚣背后的真相，并揭示了Auto-GPT不适合实际应用的局限性。


这两天，Auto-GPT------一款让最强语言模型GPT-4能够自主完成任务的模型，让整个AI圈疯了。

此前爆火的ChatGPT，唯一不太好用的地方，就是需要人类来prompt。

而Auto-GPT的一大突破是，可以让AI自我提示，就是说，这个AI完全不需要咱们人类了。

![图片](https://image.cubox.pro/article/2023041417333162205/93393.jpg)

短短七天时间，它就在GitHub上获得了惊人star数（已经突破5万），并吸引了无数开源社区的关注。

![图片](https://image.cubox.pro/article/2023041417333280757/90075.jpg)

项目地址：https://github.com/Torantulino/Auto-GPT?ref=jina-ai-gmbh.ghost.io

Auto-GPT到底有多火，看这张网友做的对比图就知道了------仅仅几天的时间，它就追平了某个红极一时项目差不多积攒了11年的star。

![图片](https://image.cubox.pro/article/2023041417333289039/20216.jpg)

不过，在为Auto-GPT狂欢的同时，我们也有必要退一步审视其潜在的不足之处，探讨这个「AI神童」所面临的局限和挑战。

近日，Jina AI CEO Han Xiao发表了一篇长文《揭秘Auto-GPT ：生产陷阱的炒作和硬道理》，与我们深入探讨了Auto-GPT究竟是一个开创性的项目，还是另一个被过度炒作的人工智能实验。

![图片](https://image.cubox.pro/article/2023041417333234923/81377.jpg)


Auto-GPT是如何工作的？


不得不说，Auto-GPT在AI领域掀起了巨大的波澜，它就像是赋予了GPT-4记忆和实体一样，让它能够独立应对任务，甚至从经验中学习，不断提高自己的性能。

为了便于Auto-GPT是如何工作的，让我们可以用一些简单的比喻来分解它。

首先，想象Auto-GPT是一个足智多谋的机器人。

我们每分配一个任务，Auto-GPT都会给出一个相应的解决计划。比如，需要浏览互联网或使用新数据，它便会调整其策略，直到任务完成。这就像拥有一个能处理各种任务的私人助手，如市场分析、客户服务、市场营销、财务等。


具体来说，想让Auto-GPT运行起来，就需要依靠以下4个组件：

1.
   架构：


Auto-GPT是使用强大的GPT-4和GPT-3.5语言模型构建的，它们充当机器人的大脑，帮助它思考和推理。

2.
   自主迭代：


这就像机器人从错误中学习的能力。Auto-GPT 可以回顾它的工作，在以前的努力的基础上再接再厉，并利用它的历史来产生更准确的结果。

3.
   内存管理：


与矢量数据库（一种内存存储解决方案）集成，使Auto-GPT能够保留上下文并做出更好的决策。这就像给机器人配备了长时记忆，可以记住过去的经历。

4.
   多功能性：


Auto-GPT的文件操作、网页浏览和数据检索等功能使其用途广泛。这就像赋予机器人多种技能来处理更广泛的任务。

然而，这些诱人的前景可能还尚未转化为Auto-GPT真正可以实现的能力。

天价的成本


想要在现实的生产环境中使用Auto-GPT，首先面临的障碍便是其高昂的成本。

由于任务需要通过一系列的思维迭代来完成，为了供更好的推理和提示，模型每个step通常都会用尽所有token。

然而，GPT-4的token并不便宜。

根据OpenAI的说法，具有8K上下文窗口的GPT-4模型，对于提示部分，每1000个token收费0.03美元；而对于结果部分，每1000个token收费0.06美元。

而1000个token大概可以换算成750个英文单词。

![图片](https://image.cubox.pro/article/2023041417333214807/22598.jpg)

让我们分解思维链中每个step的成本，假设每个动作都用尽了8000个token的上下文窗口，其中80%是提示（6,400个token），20%是结果（1,600个token）。

提示成本：6,400个token x 0.03美元/1,000个token = 0.192美元

结果成本：1,600 个代币 x 0.06 美元/1,000个token = 0.096美元

因此，**每个step的成本就是：0.192美元 + 0.096美元 = 0.288美元**

平均而言，Auto-GPT完成一项小任务需要50个step。

因此，**完成单个任务的成本就是：50个step x 0.288美元/step = 14.4美元**

* 
* 
* 
* 
* 
* 
* 
* 
* 

    VUEGPT THOUGHTS: Let's start by checking if there are any updates to VueJS. If there are, we can update to the latest version and proceed. Otherwise, we can move on to creating the TODO list website application.REASONING: Starting with the most updated and stable version of the framework will ensure our project has the latest features, bug fixes and is properly supported. Creating the TODO list website application is our primary goal, so we can move on to that if there are no updates.PLAN: -  Check for VueJS updates-  Update to latest version if there are updates-  If no updates, move on to creating the TODO list website applicationCRITICISM: NoneNEXT ACTION:  COMMAND = google ARGUMENTS = {'input': 'VueJS latest version update'}Enter 'y' to authorise command, 'y -N' to run N continuous commands, 'n' to exit program, or enter feedback for VueGPT...


以VueGPT为例：这是一个Auto-GPT创建的AI，旨在使用Vue JS创建网站应用程序，我们来看看它在思维链中的一个step

而且这还是一次就能出结果的情况，如果需要重新生成，成本会更高。

从这个角度来看，Auto-GPT目前对大部分用户和组织来说，都是不现实的。

开发与生产


乍一看，花14.4美元来完成一项复杂的任务，好像并无不妥。

举个例子，我们首先让Auto-GPT制作一份圣诞节食谱。然后，再找它要一份感恩节食谱的话，猜猜会发生什么？

没错，Auto-GPT会按照相同的思维链从头再做一遍，也就是说，我们需要再花14.4美元才行。

但实际上，这两个任务在「参数」的区别应该只有一个：节日。

既然我们已经花了14.4美元开发了一种创建食谱的方法，那么再用化相同的钱来调整参数，显然是不符合逻辑的。

![图片](https://image.cubox.pro/article/2023041417333213785/52047.jpg)

想象一下，在玩《我的世界》（Minecraft），每次都要从头开始建造一切。显然，这会让游戏变得非常无趣

而这便暴露了Auto-GPT的一个根本问题：它无法区分开发和生产。

当Auto-GPT完成目标时，开发阶段就完成了。不幸的是，我们并没有办法将这一系列操作「序列化」为一个可重用的函数，从而投入生产。

因此，用户每次想要解决问题时都必须从开发的起点开始，不仅费时费力，而且还费钱。

这种低下效率，引发了关于Auto-GPT在现实世界生产环境中实用性的质疑，也突显了Auto-GPT在为大型问题解决提供可持续、经济有效的解决方案方面的局限性。

循环的泥潭


不过，如果14.4美元真的能解决问题，那么它仍然是值得的。

但问题在于，Auto-GPT在实际使用时，经常会陷入到死循环里......

![图片](https://image.cubox.pro/article/2023041417333245611/37636.jpg)

![图片](https://image.cubox.pro/article/2023041417333237956/68591.jpg)

那么，为什么Auto-GPT会陷入这些循环？

要理解这一点，我们可以把Auto-GPT看作是依赖GPT来使用一种非常简单的编程语言来解决任务。

解决任务的成功取决于两个因素：编程语言中可用的函数范围和GPT的分治法能力（divide and conquer ），即GPT能够多好地将任务分解成预定义的编程语言。遗憾的是，GPT在这两点上都是不足的。

Auto-GPT提供的有限功能可以在其源代码中观察到。例如，它提供了用于搜索网络、管理内存、与文件交互、执行代码和生成图像的功能。然而，这种受限的功能集缩小了Auto-GPT能够有效执行的任务范围。

此外，GPT的分解和推理能力仍然受到限制。尽管GPT-4相较于GPT-3.5有了显著的改进，但其推理能力远非完美，进一步限制了Auto-GPT的解决问题的能力。

这种情况类似于尝试使用Python构建像《星际争霸》这样复杂的游戏。虽然Python是一种强大的语言，但将《星际争霸》分解为Python函数极具挑战性。

本质上，有限功能集和GPT-4受限的推理能力的结合，最终造成了这个循环的泥潭，使Auto-GPT在许多情况下无法实现预期的结果。

### **人类与GPT的区别**


分治法是Auto-GPT的关键。尽管GPT-3.5/4在前任基础上有了显著的进步，但在使用分治法时，其推理能力仍然无法达到人类水平。

*
  问题分解不充分：


分治法的有效性在很大程度上取决于将复杂问题分解为较小、易于管理的子问题的能力。人类推理通常可以找到多种分解问题的方法，而GPT-3.5/4可能没有同样程度的适应性或创造力。

*
  识别合适基本案例的难度：


人类可以直观地选择适当的基本案例以得到有效的解决方案。相比之下，GPT-3.5/4可能难以确定给定问题的最有效基本案例，这会显著影响分治过程的整体效率和准确性。

*
  问题背景理解不充分：


虽然人类可以利用其领域知识和背景理解来更好地应对复杂问题，但GPT-3.5/4受其预先训练的知识所限，可能缺乏用分治法有效解决某些问题所需的背景信息。

*
  处理重叠子问题：


人类通常可以识别出解决重叠子问题时，并有策略地重用先前计算过的解决方案。而GPT-3.5/4可能没有同样程度的意识，可能会多次冗余地解决相同的子问题，从而导致解决方案的效率降低。

Vector DB：过度的解决方案
-----------------

Auto-GPT依赖向量数据库进行更快的k-最近邻（kNN）搜索。这些数据库检索先前的思维链，并将它们融入到当前查询上下文中，以便为GPT提供一种记忆效果。

![图片](https://image.cubox.pro/article/2023041417333286578/19653.jpg)

然而，考虑到Auto-GPT的约束和局限性，这种方法被批评为过度且不必要地消耗资源。其中，反对使用向量数据库的主要论点源于与Auto-GPT思维链相关的成本约束。

一个50步的思维链将花费14.4美元，而一个1000步的链将花费更多。因此，记忆大小或思维链的长度很少超过四位数。在这种情况下，对最近邻点进行穷举搜索（即256维向量与10,000 x 256矩阵之间的点积）被证明是足够高效的，用时不到一秒钟。

相比之下，每个GPT-4调用大约需要10秒钟来处理，所以实际上限制系统处理速度的是GPT，而非数据库。

尽管在特定场景下，向量数据库可能在某些方面具有优势，但在Auto-GPT系统中实现向量数据库以加速kNN「长时记忆」搜索似乎是一种不必要的奢侈和过度的解决方案。

智能体机制的诞生


Auto-GPT引入了一个非常有趣的概念，允许生成智能体来委托任务。

虽然，这种机制还处于初级阶段，其潜力尚未被充分挖掘。不过，有多种方法可以增强和扩展当前的智能体系统，为更高效、更具动态性的互动提供新的可能性。

![图片](https://image.cubox.pro/article/2023041417333273183/35733.jpg)

使用异步智能体可以显着提高效率

一个潜在的改进是引入异步智能体。通过结合异步等待模式，智能体可以并发操作而不会阻塞彼此，从而显著提高系统的整体效率和响应速度。这个概念受到了现代编程范式的启发，这些范式已经采用了异步方法来同时管理多个任务。

另一个有前景的方向是实现智能体之间的相互通信。通过允许智能体进行通信和协作，它们可以更有效地共同解决复杂问题。这种方法类似于编程中的IPC概念，其中多个线程/进程可以共享信息和资源以实现共同目标。

生成式智能体是未来的方向


随着GPT驱动的智能体不断发展，这种创新方法的未来似乎十分光明。

新的研究，如「Generative Agents: Interactive Simulacra of Human Behavior」，强调了基于智能体的系统在模拟可信的人类行为方面的潜力。

论文中提出的生成式智能体，可以以复杂且引人入胜的方式互动，形成观点，发起对话，甚至自主计划和参加活动。这项工作进一步支持了智能体机制在AI发展中具有前景的论点。

![图片](https://image.cubox.pro/article/2023041417333283473/40384.jpg)

通过拥抱面向异步编程的范式转变并促进智能体间通信，Auto-GPT可以为更高效和动态的问题解决能力开辟新可能。

将《生成式智能体》论文中引入的架构和交互模式融入其中，可以实现大型语言模型与计算、交互式智能体的融合。这种组合有可能彻底改变在AI框架内分配和执行任务的方式，并实现更为逼真的人类行为模拟。

智能体系统的开发和探索可极大地促进AI应用的发展，为复杂问题提供更强大且动态的解决方案。

总结一下


总之，围绕Auto-GPT的热议引发了关于AI研究现状以及公众理解在推动新兴技术炒作中的作用的重要问题。

正如上面所展示的，Auto-GPT在推理能力方面的局限性、向量数据库的过度使用以及代理机制的早期发展阶段，揭示了它距离成为实际解决方案还有很长的路要走。

围绕Auto-GPT的炒作，提醒我们肤浅的理解可能让期望过高，最终导致对AI真正能力的扭曲认识。

话虽如此，Auto-GPT确实为AI的未来指明了一个充满希望的方向：生成式智能体系统。

最后，Han Xiao总结道：「让我们从Auto-GPT的炒作中吸取教训，培养关于AI研究的更为细致和知情的对话。」

这样，我们就可以利用生成式代理系统的变革力量，继续推动AI能力的边界，塑造一个技术真正造福人类的未来。

参考资料：

https://jina.ai/news/auto-gpt-unmasked-hype-hard-truths-production-pitfalls/

![图片](https://image.cubox.pro/article/2023041417333267426/37392.jpg)

![图片](https://image.cubox.pro/article/2022112406591589044/47029.jpg)

![图片](https://image.cubox.pro/article/2022102719165246216/91187.jpg)

[跳转到 Cubox 查看](https://cubox.pro/my/card?id=7047475732380911828)
