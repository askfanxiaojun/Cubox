AI经济学 \| 第二章：中国AI发展面临的挑战与应对之道
=============================

[mp.weixin.qq.com](https://mp.weixin.qq.com/s/lgiMyFG8Lp7YY_Ups3VAaA)彭虎 赵丽萍等 中金点睛

![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_gif%2FfzHRVN3sYsicmoVBv4D0mPib68kWJVkDjnEM91ZO46IRCPDfIfFpMEn2BoxwUa2fguPicQ4WwvNibdnOL4IqZj4XTA%2F640%3Fwx_fmt%3Dgif)


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_gif%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreSD3fP5MIKqToczdo81OqZJt4JiccJfHl9qdwnbN6Hc8x4thVHMTtKTA%2F640%3Fwx_fmt%3Dgif%26from%3Dappmsg)


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreV3HA4qiblt4nM5dVusKyicPXhicvBWCqGkNe5Qf3PMcrpica33ES4NQpkg%2F640%3Fwx_fmt%3Djpeg%26from%3Dappmsg)

**[点击小程序查看报告原文]()**


**Abstract**


**摘要**


**中美欧共同引领上一轮AI创新。**得益于政策支持、国内大市场以及大规模IT教育投入所带来的人才红利，中美欧在上一轮AI浪潮中一同引领全球。

**在大模型AI时代，中美差距短期有所拉大。**在全新的大模型AI时代，美国占据优势。从支撑人工智能产业的四大要素来看，模型方面，美国在数量和质量上均领先中国；人才方面，中美人才数量居前，但美国高级人才队伍更为领先；算力方面，中国算力芯片及生态系统均落后于美国，智能算力差距在中美摩擦下进一步扩大；数据方面，虽然我国数据规模全球第二，但数据质量仍落后于美国。上述要素的差距导致中美发展AI走向了不同道路，中国积极拓展应用落地而美国更专注于探索AI大模型的能力边界。

**思考与启示：新时代，中国如何应对？**在算力领域，通过持续的工程优化，海外龙头算力芯片企业与主流开源大模型的适配效果较优，这坚定了我国发展国产算力芯片的信心。此外，传统架构下芯片的持续升级遇到瓶颈，新型计算架构芯片有望帮助我国算力硬件对美国形成加速追赶。在模型层面，当前大模型遵循规模定律（Scaling Law），但无论极限是否存在，我国都应积极研发自主大模型，这不仅是技术自主和产业升级的体现，也是保障国家AI领域安全和推动科技经济持续稳健发展的关键。基于大模型的AI应用，当前尚处商用化早期阶段，国内市场面向个人和企业的应用"百花齐放"，移动互联网时代积累的应用产品经验和我国大而全的工业规模优势有望助力我国引领AI创新。在AI终端领域，中国具有全球领先的制造能力与品牌影响力，有望助力我国消费电子产业在新的AI时代实现追赶与领先。大规模市场、政策支持以及互联网时代积累的规模人才红利等是我国发展AI的优势，有望助力我国在算力层、模型层和应用层的全面追赶甚至超越。


**Text**


**正文**


**一、中美欧引领上一轮AI创新**


**在此前的AI浪潮中，中美欧在全球占据明显的领先优势。**根据中金研究院统计，2010-2023年中国在全球引用量前10%的AI顶尖文献中的发文数量占比呈现攀升态势，至2023年达到33%；根据斯坦福大学《AI指数报告》，2010-2021年中国在全球AI顶会论文被引占比同样不断增长，至2021年达到22%。综合来看，美国、中国和欧洲在全球占据明显的领先地位。中国的领先，既得益于政策支持，同时也得益于国内大规模市场以及多年在信息工程领域的教育大规模投入所带来的人才红利。


图表2.1：全球引用量前10%AI文献的发文数量占比情况和全球AI顶会论文被引占比情况


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBre8A0D3kfhMLiaOriaUfjia7Ctd2hWU601GNvBJWnbFuc3hWeFZdcmmvsEA%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


注：左图中，若一篇文献包含不同国家的作者，则按照作者数量均分到各国，数据截至2024年4月。 资料来源：Openalex，斯坦福大学《AI指数报告》（2023年），中金研究院


**（一）政策支持：从传统安防到智能物联，奠基早期AI企业发展**


**城市安防及数字化治理需求下智慧城市项目稳健增长，为早期AI企业发展奠基。**根据IDC数据，2022年我国智慧城市支出规模超过300亿美元。在政策支持下，国内大量的优质AI企业得以实现快速成长，产品能够持续迭代创新，丰富的数据也帮助了AI模型不断进步。截至当前，智慧城市类项目仍是国内AI企业重要的收入来源。


**（二）大规模市场：工业品类丰富，产值和效率不断提升**


**中国工业规模大、体系全，为AI应用奠定了良好的需求基础。**世界银行数据显示，2022年，中国工业附加值为7.2万亿美元，占全球工业附加值比重达26%。我国也是目前全球唯一拥有联合国全部工业门类的国家\[1\]。齐全的工业体系带来丰富的应用场景，庞大的工业规模带来广阔的应用需求，激烈的竞争环境驱动人工智能在工业场景的落地。

**政策支持、激烈的竞争环境和追求进取的企业家精神共同推动中国制造业智慧化转型。**过往中国制造业追求的是规模和速度，生产能力强、但品控意识弱。不过随着我国工业产品份额在全球市场大幅提升，过往的发展模式无法持续，同时伴随着生活水平的提升，人们对质量和品牌的意识不断加强。因此在激烈的竞争环境下，企业家们必须持续且快速地转型。这推动了更多信息技术和工业生产的结合，当前国内消费电子、汽车、光伏等产业已在定位组装、形状测量、缺陷检测等环节积极落地机器视觉系统。据高工机器人测算\[2\]，2023年中国机器视觉市场规模达185亿元，并有望于2024年、2028年分别超过200亿元、395亿元。此外，中国制造业面临用工成本上升、劳动力供给下降等问题，推动无人化、自动化的渗透率不断提升。

**大规模市场下会有更多需求，也带来了更廉价的解决方案。**对工业化水平不断提升的追求推动了我国产业AI过往几年的快速发展，诸如机器视觉、移动机器人等产业AI的规模落地又推动了质优价廉的大规模生产能力，从而奠定了我国在工业生产领域和行业AI应用的全球竞争力。

**中国AI市场已具备可观规模，伴随着社会智能化转型的加速正迎来更加广阔的发展空间。**根据CIC报告\[3\]，中国AI行业的市场规模在2022年已达2,250亿元，已具备广阔土壤并预期持续保持高增长，2022至2027年决策型AI、视觉AI、语音和语义AI、AI机器人分别预计年复合增长率为31.7%、21.9%、25.2%和22.3%。在规模基础之上，伴随多元垂域的智能化转型需求，中国AI软件侧发展具备有力支撑。

**垂类应用侧，中国在深度学习时代已具备竞争优势。**在计算机视觉领域，国内商汤、旷视等公司在2012年深度学习浪潮中陆续成立，以高精度视觉算法赋能城市管理和商业管理。据中研网\[4\]，截至2021年，放眼全球视频监控市场，中国市占率约47%，且国内AI摄像头整体渗透率约15-20%，远超海外市场（低于2%）。此外，国内决策AI算法多项分支已超过海外，赋能传统行业数字化转型。据Gartner 2021年报告\[5\]，国内AutoML算法在认知类问题的平均效果优于98%数据科学家，超越谷歌52个百分点；其中银行个人信用评分中，国内AutoML可实现优于99%数据科学家的准确度，超越谷歌16个百分点。据麦肯锡\[6\]报告，中国AI赋能应用潜力可观，预计到2030年，AI将为中国关键产业带来数千亿美元的经济价值。


**（三）人才红利：智能终端构筑AI应用沃土，互联网生态引领算法迭代**


**人才的培养推动信息产业，繁荣的信息产业带动人才红利。**中国是传统重视STEM学科教育\[7\]的国家，过往大规模的教育投入培养了大量信息化人才。随着互联网时代的到来，早期充足的人才储备推动了我国信息产业的快速发展。根据经济日报援引自阿里研究院的数据，2023年我国数字科技人才占全球总量17%\[8\]，领跑全球。而国内巨大的产业机遇又带来了更多人才需求，行业待遇的提高推动了年轻人学习信息科学的意愿，造就了当前我国巨大的信息技术产业人才红利。信息产业已成为我国最为吸引人才的就业方向之一，根据新华网援引自智联招聘的数据\[9\]，我国2024届求职毕业生期望行业中，IT互联网行业是应届生最向往的行业，占比达26%。

**在互联网领域，我国已依托深度学习算法红利诞生了多家具有全球竞争力的头部企业。**以电商和短视频行业为例，成立于2015年的拼多多，创新性的使用了分布式AI技术，其算法以流量分配为核心原则，基于用户需求通过推送模型实现"货找人"，为商户获客与销售增长提供了新的渠道。今日头条于2012年正式上线，在智能推荐算法的快速迭代下，TikTok实现更精准的用户内容定制化推送，打造短视频的用户高沉浸度，据Statista报告显示，截至2024年4月，创立时间仅7年的海外版"TikTok"全球月度活跃用户数\[10\]超过15.82亿，已成为全球第五大用户体量的社交APP。在激烈的竞争中，我国互联网公司早已借助AI技术脱颖而出，加速了互联网产业对于AI技术的投入。

**在智能终端硬件领域。**根据Statista和IDC数据，2022年中国在智能手机、智能音箱、智能家用摄像头、智能门锁、智能家居五大智能硬件终端品类中，均获得24%-31%的市占率，在全球市场遥遥领先。与互联网产业一样，人才叠加市场优势推动了智能化的快速发展，智能化又助力中国制造不断攻城略地，进一步推动了国内消费终端企业在智能化的投入水平。


**二、生成式AI时代，中国遇到的挑战**


**由生成式人工智能引领的科技变革渐入繁荣，应用触角广泛延伸。**2022年11月OpenAI发布基于Transformer的AI对话机器人ChatGPT，后者展现出的准确性和通用性迅速引发全球各行各业的高度关注，并在随后掀起了从基础大模型到终端应用的新一轮革新。本次变革的底层驱动是大模型语料规模大、参数规模大，例如GPT至GPT-3语料规模扩大约9000倍、参数规模扩大约1500倍。得益于"大"，用户的直观感受是模型生成效果显著增强，包括更高的输出准确度、更广泛的输出形式（不局限于文字）以及更低的输出成本，从而大大拓展了AI模型的应用场景，从早期的个性化推荐、智能客服扩展至艺术创作、办公软件交互、个人助理等，并加速自动驾驶、人形机器人等创新应用的落地。

**本轮AI新变革，美国迈出了一大步。**从支撑人工智能产业的四大要素来看，模型方面，美国在数量和质量上均领先中国；人才方面，中美人才数量居前，美国高级人才队伍建设更为领先；算力方面，中国算力芯片及系统均落后于美国，智能算力差距在美国新政限制下进一步扩大；数据方面，中国数据量全球第一，但优质数据仍落后于美国。此外，支撑AI的发展还包括PE/VC等金融支持，中国也较美国处于劣势。


**（一）模型：美国在数量和质量上均领先中国**


**回顾过往，人工智能模型源起20世纪50年代的美国，中国起步较晚。**根据Epoch AI的"知名\[11\]机器学习模型"统计数据库，最早的机器学习案例是贝尔实验室在1950年发明的"迷宫解谜"机器老鼠Theseus，其后至2013年底，美国、英国、日本、加拿大等十余个国家相继推出了182个"知名模型"，任务类型涉及视觉、语言、游戏、语音、算数、推荐等，而中国首个"知名模型"是何明凯等人在2014年发布的视觉识别网络结构SPPNet，主要是对R-CNN（2013年）的改进。截至2017年Transformer模型发布之前，美国已积累了约200个\[12\]机器学习模型，包括被广泛应用的神经网络架构CNN（1989年）、RNN（1990年）、GAN（2014年）等，而中国学者发布的模型数量不到美国的1/10。


图表2.2：国内外主要大模型参数量对比


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreoPzMDK8fH3sWu76QQNXZMwaVI6gVc9XTYHmXKprficWORVZ8kywXytQ%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


注：数据截至2024年6月5日；最新的GPT-4o、Claude 3系列模型、Gemini 1.5 Pro等大模型，官方未公布参数规模数据，故未体现在上图中。  
资料来源：Epoch AI，中金公司研究部


**当前，美国在前沿探索上更为活跃，且模型质量和认可度领先中国。从数量来看，**根据斯坦福2024 AI指数报告，2023年美国、中国分别发布61个、15个"知名模型"，而在2020年美国、中国的发布数量分别为51个、12个，在ChatGPT点燃全球AI"百模大战"之际，美国在大模型方向上的成果输出愈发活跃，并进一步拉大与中国的差距。**对比参数量来看，**GPT-4包含1.8万亿个参数\[13\]，而PanGu-Σ拥有1.085万亿个参数\[14\]。**对比性能来看，**智谱AI于2024年1月推出的基座大模型GLM-4整体性能接近美国前沿水平\[15\]，GLM-4在英文基础能力（MMLU、GSM8K、MATH、BBH等）上达到GPT-4 91-100%不等的水平，在指令跟随能力（IFEval的prompt、instruction级别）上达到GPT-4 85-90%的水平，在中文对齐能力和长文本能力上超过GPT-4。**业界认可度方面中美尚有差距，**据Epoch AI统计，截至2024年5月10日，美国AI模型相关研究中被引用次数最多的高达15.7万次（视觉模型ResNet152），语言模型Transformer、BERT则分别被引8.7万次、7.1万次，中国被引最多的约3.1万次，且被引次数前五均为视觉模型、而非语言类基座模型；AI框架的使用也存在类似差距，截至2024年5月10日，GitHub上Meta TensorFlow、Google PyTorch分别被引用7.39万次、2.11万次，百度PaddlePaddle、华为MindSpore分别被引用5400次、679次，即使在国内，TensorFlow和PyTorch的使用比例也更高，达64%\[16\]。


**（二）人才：人才是基石，中美AI人才队伍大幅领先**


**从现状看，中美两国人才储备领先他国，但中国较美国仍有差距。**推动AI发展的核心是人才，根据MacroPolo《全球AI人才追踪2.0》数据显示，2022年排名前2%、20%的AI人才中，在中美两国工作的比例接近70%，可见中美两国AI人才储备在全球处于领先地位。但对比来看，美国对AI人才的吸引力更大，中国人才培养基础不弱、但存在人才流失的难题。例如，2022年在美国完成博士学位的AI人才中有77%选择留美就业，而排名前20%且留美就业的顶尖人才中有38%来自中国（比来自美国的还多）。

**动态地看，中国人才队伍逐渐壮大。**MacroPolo数据显示，前2%顶尖人才在国内工作的比例由2019年的低于6%提升至2022年的12%，前20%顶尖人才在国内工作的比例由2019年的11%提升至2022年的28%，且在美攻读博士学位后选择在中国发展的人才比例也由2019年的4%提升至2022年的8%，反映了中国对顶尖AI人才的吸引力逐渐增强。随着国内对人工智能相关产业的进一步扶持、人工智能人才待遇的进一步提高，我们认为中国人才储备有望继续扩充壮大。


图表2.3：中美AI领域人才情况对比


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreavMicfibZJhya8sBOFhUFBib7R1AozOybV5ZvKZz4vIGcbfvomicUkgEYg%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：MacroPolo《全球AI人才追踪2.0》，中金公司研究部


**（三）算力：先发优势持续巩固，硬件基础设施与软件生态均有差距**


**1、硬件水平存在差距，供应链面临受限问题**

**算力硬件是大模型和通用人工智能技术发展的底层基础，其中算力芯片是整个硬件系统的核心。**因模型参数量、处理数据量增长迅速，对硬件性能要求也从单芯片指标维度扩展到分布式计算系统。**我们常用单芯片算力、显存及显存带宽、芯片间互联带宽、节点间互联带宽等核心指标衡量算力硬件的系统能力，各指标相辅相成，不存在明显短板的系统才可称之为"优质算力"。**在上述评价体系下，我们看到美国产品全球领先，且具有明显的先发优势，全球算力产业链被著名芯片设计企业英伟达（NVIDIA）所引领。英伟达以其GPGPU（General Purpose Graphic Processing Unit，通用计算图形处理器）架构产品垄断算力芯片市场，根据Precedence Research提供的数据，2022年全球AI芯片市场中英伟达份额占比超过80%，且提供从芯片到系统的全栈解决方案。

**中国大陆企业积极把握国产化浪潮，对算力硬件实现全面布局。**核心芯片端，除老牌设计企业华为海思深度参与其中外，得益于此前多年半导体产业相对宽松的融资环境，创业者热情被充分激发，市场上也诞生了一批实力不俗的新生代力量。技术路线上，中国芯片公司选择呈现分化，除效仿GPGPU路线外，DSA（Domain Specific Architecture，专用领域处理器）技术路线也受到青睐。此外，与算力芯片合封的高带宽存储器以及算力芯片互联所用到的物理层IP、光模块、交换芯片等其他产品上，中国自主供应能力也逐步得以补齐。采用上文"优质算力"的评价体系衡量，**我们认为中国大陆产品当前水平较美国仍存在几年差距（图表2.4）。**


图表2.4：中美算力硬件差距


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreRkMptVXmpmFEicN6NSPXgRyMAib2llQW7yPLZiaH4sKwfUEcexFpYdT8Q%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：英伟达官网，中金公司研究部


**在追赶美国的道路上，芯片供应链问题出现掣肘。**尽管在芯片、系统设计本身方面中国企业取得了快速进步，但供应链端依然存在较大不确定因素：美国商务部分别于2022年10月、2023年10月\[17\]通过逐次趋严的出口管制规定来加强限制中国大陆直接获取高端算力芯片产品及配套存储芯片产品、或是获取制造高端算力芯片所用的技术、设备等，还将部分芯片设计企业列入"实体清单"。**复杂的国际环境进一步加大了中国大陆在芯片端加速追赶的难度。**

**2、系统生态存有差距，追赶难度较大**

**中美在算力领域的差距不仅在于硬件本身，系统生态壁垒使英伟达产业链的先发优势得以不断加强。**从算法开发者编写基于Python语言的代码，到底层GPGPU硬件可执行的二进制机器码之间涉及了多个步骤的传递，其中蕴含着大量编译技巧和系统优化。整体流程上来看，算法开发人员在开源框架上采用Python代码编程后，由框架转换成计算图（模型结构），并生成对应算子（计算操作，即对何种维度的数据进行何种方式的处理）。而算子的硬件实现是通过英伟达统一高层次抽象的GPGPU编程语言CUDA来编写的。针对不同领域的常用算子，英伟达还开发了多个针对性的加速库，在涉及分布式计算时，英伟达同时也配套开发了多个通信库以适配多种分布加速框架。同时，英伟达也拥有高效的编译器，以全方位维度配套算法在芯片上能得到最优化、最高效的执行策略（图表2.5）。


图表2.5：一颗英伟达GPGPU芯片上层支撑了丰富的系统生态


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreUaOCbLWj8RZtdWPZoemIqxTMccI6w4XFlolPvqFjkJBLWY574vekxA%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：英伟达官网，中金公司研究部


过去10多年人工智能行业发展过程中，硬件的几乎唯一性使英伟达产品库与当前全球庞大的PyTorch框架开发者、CUDA开发者群体深度绑定，英伟达对未来的算力硬件产品迭代方向自然有着清晰的认知。**做形象的比喻来看，其他硬件企业研发新品是"闭卷考试"，而英伟达是"开考前已知晓答案"。**而在算子的适配优化、多卡并行计算通讯优化、以及高可靠集群系统构建等方面，其日积月累的护城河也绝非短期可以破除。英伟达持续的投入研发和精力使整个软件栈变得易用，新进入者短期内难以企及。**我们认为英伟达以外的竞争对手在算力硬件侧实现加速追赶的难度较大：**

**第一，对于国内企业来讲，兼容CUDA代码是短期内能够实现硬件商业化落地的较优选择，但存在一定弊端。**以To B商业模式的直观逻辑来看，由于系统生态壁垒的存在，硬件的切换成本被抬高，假设不考虑其他因素，性能高于竞品很多的产品才可能被考虑。从中短期的现实角度来看，业内认为兼容CUDA是一条较为容易实现生态建设的路径。但CUDA代码是基于英伟达硬件上的统一编程语言，CUDA本身除源代码属于开发者所有外，一切基于CUDA的产物均是不开源的，属于英伟达的专有产品，中国企业在生态迭代方面占据主导地位的可能性较弱，在兼容中也难免会遇到长尾问题，经由此路实现加速赶超的难度较大。

**第二，自行重新构建系统生态可避免迭代上的被动和兼容带来的问题，但难度可能更高。**根据上文所述，整体算力硬件生态系统的构建可以被拆分为以下若干环节：

**►** 传统主流框架算子适配：在训练端，当下AI训练框架意义重大。AI框架可以将开发者编写的神经网络模型及代码转化成计算图，可供计算机识别并执行，同时可以提供编程接口支持，提供灵活的编程环境和编程体系供开发者接入。而计算图之间经由算子进行连接，因此我们认为单卡对训练框架所包含的算子实现全面支持和跑通是生态兼容的第一步。出于开发成本考量，国产厂商一般选择的方式是先去支持更广泛被使用的算子，而对于小众算子一般会采用主流算子拼接的"兜底策略"实现。算子开发面临着大量的劳动，当下PyTorch 2.0版本包含2000多个算子，我们认为相关从零到一的适配可能会等于百人工程师团队1-2年的工作量。在完成适配以后，算子的执行也需要被不断优化，来实现更好的软件到硬件端性能。

**►** 构建分布式通信库，兼容或开发并行加速框架：由于大模型的训练需要多硬件协同完成，因此在实际训练模型过程中，除了使用当前PyTorch等主流训练框架外，还需调用并行加速框架如DeepSpeed（微软维护）、Megatron-LM（英伟达维护）等，以实现对数据并行、模型并行、专家并行等多类并行策略；同时，物理通信的实现也要配套硬件的通信库来完成，提供跨机跨卡的通信能力并能根据底层网络特点充分利用网络带宽。

**►** 建立集群的容错机制：机器在执行大规模分布式训练任务时候负载重，发生错误概率高。在硬件配套的系统软件端，也要考量硬件发生故障后快速恢复模型训练的能力。短期内通过写checkpoint的方式完成，长期看需学习Spark的容错机制，在数据并行的节点间自动容错。

**►** 构建推理引擎：在实际应用中，模型的推理阶段同样需要高效的计算支持。与训练时需要大量的零散的小算子所不同，推理情况下多采用大算子。如何进行算子融合、低精度加速、矩阵乘法的张量加速、多卡并行是推理引擎的技术关注重点。我们看到，目前训推一体框架也是国产企业正在尝试的方向，旨在用单一框架去实现对训练、推理的多维度加速。

总结来看，算力硬件系统生态的重新构建需要在上述四个环节上进行大量的人力投入，实际效果优劣也与工程师的经验加成密切相关。更关键的是，**在过去的行业发展过程中，国产算力硬件系统生态完备搭建的速度较缓慢，进而导致了中美在AI算力硬件端差距拉大。**


**（四）数据：数据是本轮人工智能的血液，中美之间围绕数据的质和量展开竞争**


**数据是大模型的原料，且存在集中化趋势。**本轮人工智能的基础之一是越来越多的数据量，因此大模型竞赛的背后也是数据规模的竞争，目前全球大模型使用的大部分数据来自于维基百科、爬虫等网络渠道，以及书籍、学术期刊等，以英文数据为主，中文数据占比较少。聚焦在数据的分布上，根据论文\[18\]，举例Papers With Code这一机器学习社区，其中的基准测试数据集集中在全球少数机构手中，且集中度随着时间推移提升，存在不平等分配的现象。

**当前中美在数据的质和量方面展开竞争。**在量的方面，根据IDC，中国数据量规模全球第二，仅次于北美\[19\]。但未来随着高质量数据或将逐渐耗尽，合成数据有望成为新的解决方案，且对数据量的要求也逐渐提高，因此如何获取更多数据及进行数据合成将成为新的竞争重点。在质的方面，由于高质量数据能够显著提升模型效果（图表2.6），因此数据质量的提升能够达到事半功倍的作用，聚焦中国看，中国移动互联网、智能汽车等众多领域的蓬勃发展，或有望促进To B/C端数据质和量的提升，助力中国在大模型所需的数据方面实现赶超。


图表2.6：高质量数据可以显著提升模型效果


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreicdXibwhgZhn5S5e2DLIUKyMSujo9WibslB7ibZpxiaxxl0U1E0zZHTbmEQ%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：Textbooks Are All You Need\[20\].中金公司研究部


**综合来看，中美资源禀赋的差异可能将引导中美AI发展走向不同道路。**受限于人才、算力、数据等方面的差距，客观制约使得中国较难通过"堆算力、堆参数"的模式发展人工智能大模型。同时，短期内发展自主算力的试错成本较高、大模型的商业化逻辑不清晰，这些都意味着短期内攻坚薄弱环节的风险较高，需要更长时间经验的积累。而规模效应方面体现出的比较优势，结合政策层面的积极推动，使得中国在AI应用环节的探索较为领先。

**而美国则在AI前沿技术发展上具有明显的比较优势，能够支撑其在"更大算力规模、更大数据范围、更大参数体量"的尺度上，持续探索"规模定律"的边界。**2017年谷歌发布的Transformer本身参数规模在1亿个，此后谷歌BERT（2018年，3.4亿）、OpenAI GPT-2（2019年，15亿）、谷歌T5（2019年，110亿）、OpenAI GPT-3（2020年，1750亿）、谷歌SwitchingTransformer（2021年，1.6万亿），参数规模的数量级不断刷新。近来，GPT-4、Claude 3、Sora等模型层出不穷，我们看到AI大模型的性能持续提升、模型迭代速度依然较快。受此影响，基于前代大模型开发的应用，尽管初期性能效果不错，但或许很快将面临基座大模型升级后应用性能再次落后的问题。这样，基于旧大模型开发的应用很有可能在新模型诞生后因性能、成本等全面落后而丧失竞争力。因此，基座大模型的快速升级迭代会影响到商业应用的开发节奏。目前看，美国大模型产业尚未进入成熟阶段，处于不断动态升级中，在这种情况下规模发展应用可能是不够经济的，因此沿着"规模定律"探索性能边界更符合美国当前的商业逻辑。


**三、思考与启示**


**展望未来，我们拟提出中国在大模型时代机遇面前的应对之法。**AI产业架构自下而上可分为算力层、模型层、应用层，我们认为，中国在算力层有望通过国内巨头自研与算力扶持逐步破局、全新的计算架构或将带来新变数；模型层应踏浪后发机遇、坚持主权AI下的自研追赶；应用层则依托研发工程师红利、数据基础和产品生态迎来本土机遇。


图表2.7：AI产业架构一览


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBre1w2a8C4LQkvU2VF0RsREEibDDt0CwAIL4TZCANY0Snroic8vYjBQPIjw%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：中国信通院，中金公司研究部


**后文将根据架构图进行逐层探讨：1）算力层以智算中心（AIDC）为载体、以AI芯片为核心。**当前AI芯片以GPU架构为主，美国拥有先发优势，中国起步较晚，使得当下两国在AI芯片性能和生态上的差异巨大，下文将从可行性和新的突破口两个维度探讨芯片领域如何追赶。**2）模型层分为平台软件层和算法模型层。**平台软件层是支撑AI模型大规模训练、生产部署的技术体系，包括数据清洗及合成平台、训练框架、推理部署框架、模型生产平台，为深度学习算法的工程实现带来核心竞争壁垒；算法模型层是特殊的软件，包括预训练大模型和计算机视觉、自然语言处理等小模型技术，为AI企业结合算法技术经验和产业实践中的模型成果沉淀。本文主要基于大模型的本质、应对差距的方式展开探讨。**3）应用层基于AI算法模型的赋能，以To C应用或To B解决方案的形式实现场景落地。**在长期趋势下，大模型也有望承担操作系统角色，衍生出终端硬件、代理（Agent）的"百花齐放"机遇。


**（一）算力层：算力领域追赶的可行性和突破口**


**1、可行性：海外龙头算力芯片企业已实现在开源模型端的较优适配**

在上文中我们指出，龙头企业英伟达不仅在算力芯片领域处于全球垄断地位，在整个算力硬件系统层面也有极高的生态壁垒。过高的算力硬件系统供应集中度引发了海外人工智能业者对于供应链风险的担忧，开始寻求算力硬件供应链多元化。**目前，在开源模型的硬件适配上，随着AMD、Intel等企业算力芯片产品性能的不断提升、系统生态的进一步完备、工程优化不断推进，我们已经看到了良好的结果：**

以Intel Gaudi 2为例，基于LLM Foundry的训练框架及Optimum Habana推理加速库，在经历长达数月的优化后，DataBricks已经在其MPT系列开源模型、以及Meta主导研发的LLAMA开源模型上得到了较好的适配效果\[21\]。在MPT-7B模型上，实测Intel Gaudi 2处理器8卡训练计算性能已超过260TFLOPS每卡，超过英伟达A100-80GB/40GB硬件表现。在多卡方面，160卡集群也保持了良好的近似线性的加速比（由于卡间通信存在时间开销，因此随集群规模增大，线性加速比水平会下降）。同时，在推理方面，基于LLAMA2-70B模型，8卡Intel Gaudi 2系统的解码时延也几乎与8卡英伟达H100系统相同（解码时延为大模型推理中成本最敏感的部分）。且从成本端来看，使用Intel的Gaudi 2处理器做训练或推理，开销仅为英伟达产品的40%-50%（图表2.8）。

**AMD、Intel等企业的算力硬件产品对主流开源大模型的较优适配，坚定了我们对国产算力硬件商业化落地的信心。**特别的，若短期内部分国内大模型是以微调主流开源模型形式做开发，此情形下适配的专注度呈现提升（即模型结构趋于统一后，硬件的适配优化方向也会愈发明确），会加速适配落地的节奏。


图表2.8：Intel和AMD的经验：开源模型上，英伟达的护城河并非坚不可破


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBre77dMKfGGYIhT4BJr41dfTBS7mMibDicBNV2jBA512wK4b2iaGgqM0aJsw%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：DataBricks，中金公司研究部


**2、突破口：贸易摩擦打破过往商业逻辑，政策支持孕育加速追赶机会，新硬件架构带来新机遇**

前文中，我们阐述了受供应链限制、系统生态壁垒等因素影响，在算力硬件领域存在强者恒强的固有商业逻辑，导致中美产品的差距在此前不断拉大。**但是，当下贸易摩擦大环境、政策端对半导体及AI产业的支持、芯片技术路线差异化发展等因素也为国产算力硬件实现加速追赶带来了突破口。**


图表2.9：算力成本下降来源于多维度贡献


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBrepCiancu5fY8O0GC6q9yziaFugmBhaaWCPE9bgk1kjjMdbGZIT0SibVefw%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：英伟达官网，中金公司研究部


**贸易摩擦打破了算力硬件产业过往强者恒强的商业逻辑，政策端鼓励的国产化产品采购给国产算力硬件技术指标、系统生态快速进步提供了条件。**国产算力芯片及算力硬件系统虽在此前宽松的资本市场环境支持下得以快速发展，但由于过往强者恒强的固有商业逻辑，国产产品很难获得被市场检验的机会，在新品定义上可能与实际需求存在偏差，系统生态也十分薄弱。但恰恰是受到了贸易摩擦大环境的影响，当下AI算力芯片国产化迫切，政府、运营商等客户的实际采购可为算力硬件供应商提供难得的商用机会和及时的产品反馈，对于芯片、算力硬件系统研发的迭代具有正向作用，能够快速帮助国产产品从"能用"走向"好用"。固有商业逻辑的打破，为国产算力硬件实现加速追赶提供了可能性。

**定制化架构、创新型计算架构同样带来加速追赶机会。**当下算力市场存在降本的迫切需求，算力普惠能加速推动硬件投资与大模型商用落地形成闭环。在硬件降本的核心思路上，除了通过芯片制程迭代增加晶体管密度外，采用定制化架构（DSA）设计芯片也是一个可行思路。特别是在当下Transformer成为主流模型架构后，更多的优化是对注意力机制层（Attention Layer）的堆叠、对注意力机制头（Attention Head）的调整，这些调整并不会引起硬件端先前的最优架构设计失效。且在推理端来看，定制化的架构有望带来成本的大幅优化，符合当下的市场需求。

对于未来AI算力发展，无论"规模定律"的极限短时是否会被发现，Transformer的技术路径是否会被颠覆，大模型整体计算量的需求增长持续性是确定的。面对当前摩尔定律、冯诺依曼架构芯片支持算力市场需求增长日渐乏力的痛点，**研发近存计算、量子计算、光子计算等创新型计算架构芯片是行业未来可能的发展方向。鉴于当下创新型计算架构并不存在成熟的解决方案，我国算力硬件企业通过"换道"实现对美国加速追赶可能性增加，**但这也对我国相关人才的创新能力提出了更高要求。


**（二）模型层：底层模拟人脑机制，商业价值具备规模效应**


**1、模型层的"物理属性"是什么？**

**模****型层"物理属性"是以主流连接主义为背景，底层不断模拟人脑神经元的工作机制。**深度学习神经网络是基于多层感知机理论发展起来的，引入了多个隐藏层并不断优化算法来实现学习效果的提升。1986年，BP算法被提出\[22\]，具有很强的函数复现能力；1998年，LeNet-5模型出现\[23\]，是第一个正式的卷积神经网络；2006年，深度信念网络模型问世\[24\]，掀开深度学习网络复兴的序幕；2012年，深度神经网络走向商用，发展迎来高峰。

**实现通用智能需要"量变到质变"，大模型参数量已达到万亿级，但与人脑突触的数量级还存在较大差距。**低级的动物智能进化到人的智能的过程中，并没有明显的分界线，智能本质上是量变到质变的过程。研究发现，线虫是最简单的有神经系统的生物之一，身体共约1,000个细胞，其中302个为脑细胞\[25\]，全部神经元之间约7,000个连接\[26\]。人脑中约有10的11次方个神经元、10的15次方个突触。与生物智能类似，人工智能也正在通过积累量变持续提升，最终有望实现质变。人工智能模型的算力提升主要通过提升深度学习中层体的深度和每层神经元的连接稠密度，从而实现神经元总数量和单个神经元连接的数量提升。当前大模型的万亿级参数，与人脑突触的数量级尚存在较大差距。

**模型层实现"量变"的前提是重前置投入，进而带来落地的低边际成本。**对于通用智能大模型而言，重前置投入者方能带来低边际成本。大模型底层模拟人脑通用智能，蒸馏出的小模型体现出更强的泛化能力，且边际成本大大降低，从通用大模型到小模型蒸馏落地的路径已经成为产业界主流方向。在训练大模型背景下，资本壁垒、技术壁垒极高，为AI巨头之间的博弈。资本壁垒主要体现在算力集群使用成本，斯坦福HAI研究所测算GPT-4和Gemini Ultra的训练成本分别高达7800万和1.91亿美元\[27\]。据Translink Capital，截至2023年底，全球范围内大模型厂商累计融资额超140亿美元。技术壁垒包括显存问题、芯片间通信问题、万卡集群的工程难度、计算资源利用率的挑战等，均考验综合能力。

**预训练大模型高前置投入，在大模型产业链成本中占比最大。**据微软Build 2023开发者大会，模型预训练需基于千卡-万卡算力集群并耗时数月完成\[28\]，时间比重占总训练过程的99%以上\[29\]，其算力与时间成本为后续部署落地的数十倍。英伟达GTC 2024大会提到，1.8T参数量的GPT-MoE模型需要用8000张H100训练90天\[30\]。考虑到预训练的高前置投入，模型层与应用层厂商形成明确分工。

**大模型落地边际成本持续下探，部分领域已打破劳动力市场均衡，有望实现规模化推广。**根据《ARK：Big Ideas 2024》，以2023年3月14日发布的GPT-4-32k为基准，2023年11月6日发布的GPT-4 Turbo实现推理成本下降92%、上下文窗口长度提升4倍、处理速度提升4倍。由此可见，推理成本不断优化，模型性能边界持续扩容。在推理成本下探趋势下，AIGC赋能文案撰写等领域已实现成本骤降，打破原有劳动力市场均衡。据ARK统计，每千字文案撰写的人工成本超100美元，GPT-4 32k能以中等GRE辨析写作水平将成本下压至0.16美元，Claude 2将成本下降至0.04美元，性能进一步提升，当大模型突破以GPT-4为代表的技术临界点，落地边际成本有望趋近于互联网时代的零分发成本。

**2、如何理解大模型时代的规模定律？**

**大语言模型遵循规模定律（Scaling Law），即大语言模型性能随着模型规模的指数级扩大呈线性改善，当提升模型参数量、数据量或计算量时，模型表现会更优。**根据Kaplan Scaling Law\[31\]，控制模型参数量、数据量、计算量三者其二恒定，模型性能与前述各因素均呈现幂律关系。为了达到最佳性能，模型参数量、数据量和计算量必须协同扩大。此外，Kaplan Scaling Law指出大参数模型较小模型更具样本效率，能够在更少的数据和优化步骤中达到相同性能水平；算力固定时，增加模型参数量对模型性能提升的贡献将大于单纯增加数据量或改进数据输入方式。

**Hoffmann Scaling Law\[32\]与Kaplan Scaling Law大致类似，但认为在给定算力限制的情况下，模型规模与数据量应被赋予相同权重。**DeepMind在使用不同规模的数据（从5B到500B tokens）训练超过400个不同大小的模型（从70M到超过16B）后发现，模型参数量和训练数据规模需要等比例增大，才能达到最优训练效果，而Kaplan Scaling Law则倾向于为增加模型参数量分配更大权重。


图表2.10：大模型性能与计算量、数据量和参数量呈幂律关系，三者需协同扩大带来性能提升


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBre7Nic4fQR38ibxfMkEcIgRI19t8nFmbMqNaic7OLFhfQP5icWco6sjj5jqQ%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：Jared Kaplan, et al. Scaling laws for neural language models, January 2020，中金公司研究部


**目前业界和学界就规模定律是否存在极限有分歧，反方主要针对现阶段大模型的理解世界能力\[33\]和未来发展的可能性边界提出质疑，正方则认为目前规模定律尚未达到极限，并就上述质疑提出反驳。**

**反方观点认为，随着模型规模指数级增长，模型或面临诸多关键技术原理及性能边界的挑战。1）高质量数据或被耗尽：**根据Pablo Villalobos等人的研究，高质量语言数据、低质量语言数据和图像数据或将分别在2026年、2030-2050年和2030-2060年耗尽，若未来数据效率没有大幅提高或没有新的数据来源，规模定律或将不再具有可实施空间\[34\]。**2）参数效率低下：**根据Hoffmann Scaling Law，参数量应与训练数据规模等比例增大，但是目前部分大模型的训练数据集规模相对较小，无法与其庞大的参数量相适配，导致模型中存在冗余参数，影响模型泛化能力和总体表现\[35\]。**3）梯度不稳定：**随着模型规模和序列长度的增加，训练损失和梯度方差的波动更大，导致模型训练时的稳定性下降，难以收敛\[36\]。**4）长期任务困境：**目前基准测试主要分为两类，a.评估模型的记忆、召回、插值能力，例如MMLU、BIG-bench和HumanEval，b.长期任务执行或处理复杂概念，例如SWE-bench和ARC。大模型在前者展现出和人类相当的水平，而在后者表现并不出色。以SWE-bench测试为例，大模型需自主处理拉取请求（Pull Request）任务，GPT-4和Claude2分别只能完成1.7%和4.8%，这表明其在处理长时间跨度的复杂信息的能力仍有较大提升空间\[37\]。**5）无法真正理解世界：**深度学习先驱Yann LeCun认为真实物理世界的理解和推理需要依赖"世界模型"\[38\]，目前主流大模型主要基于自回归路径，不同于人类的思维方式（能够融会贯通、举一反三），无法真正理解世界，因而不是通往AGI的有效途径；仅依靠模型规模的增加（即Scale up）并不能解决所有问题，特别是在模型达到一定规模后，性能提升可能会遇到瓶颈，因此算法创新和架构改进具有重要意义。斯坦福大学教授李飞飞指出，通用智能的基本特征之一是感觉（sentience），即具有主观经验（例如感到饥饿和看到红色），而大模型是数学模型，没有生理状态，不具备感觉能力\[39\]。**6）是经验性定律，而非自然定律：**规模定律并非类似重力的自然定律，而是类似摩尔定律的由人类观察得出的经验性规律，其正确性有待进一步确认，而摩尔定律自十年前已开始放缓，规模定律未来或面临边际效益递减，并体现在真实性、推理能力和常识水平等指标上\[40\]。

**正方观点认为，规模定律是大模型的第一性原理，且尚未达到极限。1）合成数据有望缓解高质量数据即将被用尽的担忧：**合成数据可以减少对真实世界数据的依赖，提高数据质量，可用于构建虚拟环境、增强交互体验，拓宽应用边界\[41\]。**2）硬件能力提升、模型架构和训练方式更新有望进一步提升规模定律的潜力：**硬件层面，芯片设计优化、芯片制程迭代、互联效率提高等硬件能力提升、更高效的计算资源利用、量子计算等计算架构创新，会继续支持大模型的能力升级；软件层面，采用MoE（混合专家模型）架构\[42\]，结合剪枝、量化和蒸馏等技术\[43\]，可以简化模型架构，提升模型性能和效率。**3）大模型或具有人类心智：**Nature子刊最新研究指出，GPT-4在心智理论多方面或超过人类，其中，GPT-4在反讽、暗示、奇怪故事测试项目中表现明显优于人类，错误信念项目中与人类持平，仅在失言项目中弱于人类，或系其相对谨慎、不轻易给出确定性意见\[44\]。

**国内外技术背景的部分人工智能创业者对规模定律的通用潜力存在信仰。1）**月之暗面（Moonshot AI）创始人杨植麟\[45\]指出，因为模型架构足够通用且可规模化，因此规模定律是第一性原理，AI领域唯一有效的是Next Token Prediction + Scaling Law，只要token足够完整，理论上一切模型能力都是可期的，并且应同步推进User Scaling和Model Scaling。**2****）**北京智源研究院创始理事长张宏江\[46\]指出，目前AI技术发展水平较Transformer架构的极限还有较大距离，当前问题可能是数据量不足，因此重心应放在尽可能扩大数据规模上。**3）**零一万物技术副总裁黄文灏\[47\]更是直言"Scaling Law is all you need"，大模型的训练动态（Training Dynamics）完全可以被建模，其训练表现也完全可被预测，例如在100M以下规模的模型上做的实验拟合公式，可以准确预测数十亿甚至百亿参数量模型训练过程中每一步的验证损失（Validation Loss）。**4）**Anthropic创始人兼CEO Dario Amodei\[48\]认为未来规模定律大概率不会停滞，即使未来大模型能力迭代速度有所放缓，也更应该归因于计算架构等其他因素。

**3、模型层的"先发优势"是否一定成立？**


图表2.11：在规模定律极限探讨的基础上，先发优势和后发优势的观点之争


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBrewsIY29U78ic8RVxzpuvLD7xbCWrweeQ28M1Rx64JcS8YXsI3JSnFmUQ%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：中金公司研究部


**在规模定律极限探讨的基础上，先发优势与后发优势的观点之争同样存在。当规模定律存在极限（反方观点），当前大模型技术路线仅为中间态，模型维度先发优势不显著，但商业视角的先发优势仍部分成立。****从技术视角看，**参考Transformer之于RNN架构、GPT之于BERT路径均为后发者，未来模型架构或迎来颠覆式创新，后发者通常承担较少的技术负债，并具备较低的迁移成本；基于模型架构或被颠覆的假设，后发厂商还有望节约试错成本，并通过开源模型积累工程经验，即使数据的合成能力与真实数据基础、模型成熟度有关，其在合成数据方面也具备一定追赶机遇。**从商业视角看，**一方面，算力成本有望随芯片技术优化而逐渐降低；另一方面，先发厂商建立的品牌优势很可能被后发厂商通过更完善、更贴合特定需求的产品或客户的"二供"需求（基于供应链风险和成本考量）所抵消，因此算力成本和品牌效应方面均利好后发厂商；而资本和人才天然具有聚集效应，先发厂商有望率先聚拢上述资源，后来者存在无法高效实现资源汇集的风险。

**规模定律不存在极限的假设下，工程化能力与资本正向赋能迭代，模型侧到商业侧的先发优势显著。从技术视角看，**若当前技术路线明确，先发厂商有望在持续率先迭代模型的同时，积累海量高质量数据和丰富的数据清洗、数据标注、模型调优等方面的工程经验，全方位持续扩大领先优势；而后发厂商或只在试错成本方面具有相对有限的后发优势。**从商业视角看，**在大模型商业化落地初期，先发厂商有望率先占领用户心智，推进User Scaling，由于资本、人才和品牌效应对相关厂商发展的促进作用相辅相成，更多的资本、人才积累和更快的商业化落地进程或为先发厂商带来明显的领先优势；而算力成本随着芯片优化、模型创新始终具备下降空间，后发者具备成本优势。

**4、预训练大模型的成本、性能探讨以及风险规避**

**预训练大模型的算力需求与参数量及训练数据集大小正相关。**对于Transformer大模型，其模型训练的算力需求公式大概为：C ≈ 6ND（N为模型参数量，D为训练数据量）。基于上面的公式，可以对于GPT-3、GPT-4这类的大语言模型所需算力进行测算，若以7天作为单次训练时长，得出GPT-3这样的千亿参数模型训练需要的DGX A100/H100数量大概为500/80台；GPT-4这样的万亿参数模型用30天进行训练，所需要的DGX A100/H100数量大概为4,400/700台。

**算力成本占大模型训练开支主要部分，GPT-4单次训练成本可达千万美元级别。**如果采用全部算力购置的形式，按照目前DGX A100/H100的价格，如果对于训练所需要的算力都采用购置的方式，则训练GPT-3需要的资本开支在3,000-8,000万美元（7天训练一次）；训练GPT-4需要的资本开支在3-10亿美元（30天训练一次）。如果采用云上算力租赁的形式，按照目前A100/H100的云上租赁价格，我们测算出GPT-3单次训练的成本在40-120万美元；而GPT-4单次训练的成本在1,500-5,000万美元左右。而一般语言领域的模型训练1-3次Epoch即收敛，因此采用租赁而非购置的方式一般会更为经济，但前者购置的算力也可以为后续推理准备。除了算力成本之外，研发人员薪酬、电费等带来的其他成本相对占比较小，并不构成主要的成本项。


图表2.12：GPT-3\&GPT-4级别大模型预训练的成本度量


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBredQph9pfPFeoLCGt5YtFrsibNYHOek6dIPcOeUy4J2C8YETx5qzBz1sQ%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：OpenAI官网，Nvidia官网，中金公司研究部


**微调大模型具备成本优势，业界对于套壳微调的性能优势具备分歧。**在人工智能领域，套壳模型（Wrapped Models）作为一种成本效益较高的方法，通过在已有的基础模型上进行微调，以期达到与闭源模型相近的性能。根据Hao Liu等人的研究\[49\]，OpenLLaMA作为一个开源的套壳模型，其性能与基础模型LLaMA相近，这表明在同等参数量下，套壳模型能够实现与基础模型相似的性能表现。此外，Alpaca模型，由斯坦福团队基于LLaMA 7B进行微调\[50\]，其训练成本显著低于闭源模型GPT-3.5。Alpaca在8个80GB A100上训练3小时，训练成本不足600美元，而GPT-3.5的成本则显著更高。在人工评估中，Alpaca与GPT-3.5的获胜次数分别为90和89，显示出性能上的相似性，这进一步证实了套壳模型在成本上的优势。

**然而，业界对于套壳模型的性能优势存在不同的声音。**Arnav Gudibande等人的研究\[51\]表明，尽管套壳模型能够模仿ChatGPT的风格，但在事实理解和推理能力上存在不足。特别是在进行大量模仿数据训练时，套壳模型与闭源模型之间的性能差距并未缩小，反而有所扩大。在谷歌QA基准数据Natural Questions的考核中，当数据量达到150M tokens时，套壳模型的准确率不及ChatGPT的50%，这表明套壳模型在未训练过的任务上的泛化能力有限。因此，研究认为构建更加强大的基础模型是提升性能的关键，简单地依赖套壳或模仿难以达到优秀的泛化性能。

**依托于主权AI，依赖开源模型存在诸多风险，中国自研大模型具备必要性。**在全球化的人工智能领域，开源模型因其成本效益和易于获取的特点而广受欢迎。然而，随着地缘政治问题的上升，交易成本的增加，传统的分工带来的效率增进正在被逐渐侵蚀。从产业链安全的角度来看，发展具有主权控制的人工智能技术变得尤为迫切。科技创新的激励机制往往是"赢家通吃"（Winner takes all），但地缘政治的变化使得这种模式不再得以适用，从而为发展主权AI提供了战略机遇和经济激励。

**开源社区的政治立场也可能对技术发展产生影响。**例如，在2022年俄乌冲突爆发后，包括Github在内的多个开源社区宣布了政治立场，限制了俄罗斯的使用，这一事件凸显了依赖外国开源社区的风险。此外，开源项目的可持续性依赖于项目维护者的持续投入，但维护者的变更、政策的变动或恶意操纵都可能使项目变得不再安全。除了供应链风险，依赖开源模型还可能带来合规风险和效益风险。合规风险主要体现在训练数据源的处理上，不当处理可能导致模型偏差，影响模型性能和公信力。效益风险则涉及到远期维护成本和模型的可拓展性，闭源模型能够更有效地根据具体需求进行调整，而开源模型可能需要额外的开发工作才能满足特定要求。

**因此，中国自研大模型的开发不仅是技术自主和产业升级的体现，也是保障国家AI领域安全和推动科技经济持续稳健发展的关键。**通过自主研发，中国可以更好地控制数据流向，保护用户隐私，同时确保技术发展不受外部限制。此外，自研大模型能够更好地适应中文语境和文化特性，提供更符合国内用户需求的智能服务。通过加强研发投入，鼓励创新合作，并结合国内外的优秀研究成果，中国有望在人工智能领域实现更多突破，为全球科技进步贡献中国智慧。


**（三）应用层：经济属性带来先发优势，供需催化有望后发追赶**


**1、应用软件赛道，天生具有"先发优势"的特征**

**应用软件具备前置成本较高而边际成本趋近于0的经济属性。**Cristensen, Ghose和Mathur(2020)的研究指出，软件作为数字经济的典型代表，有明显的边际成本趋于0和非竞争性等属性，其变动成本低，而开发、测试等前期投入成本较高\[52\]。Kollock(1999)的研究也指出，软件产品是信息，而不是对于企业生产有明确规模经济的物理产品\[53\]。对于软件企业而言，由于代码复制只需极低的成本，因此通常服务一个新的用户的边际成本是很低的。

**掌握"标准"甚至定义"标准"有助于应用软件抢夺全球市场的关键卡位。**软件行业的事实标准是由企业发起并被市场广泛接受的规范，比如数据库行业的SQL标准、办公软件领域的.docx/.pdf标准等。由于标准具备网络外部性和公共品属性，企业可以通过掌握"事实标准"而在竞争中占据优势地位，例如作为全球第一个将SQL规则商业化为数据库产品的厂家Oracle，助推SQL在1986年成为美国国家标准协会的行业标准，并借由SQL的推广使得其数据库在全球占据优势份额。

**"标准"的力量赋予应用软件明显的"先发优势"特征，容易走向"赢家通吃"的市场格局。**首先，在应用软件行业发展的过程中，往往先发者能够抢占制定"标准"的话语权，进而在后续的市场竞争中掌握优势卡位；其次，应用软件具备网络效应，先发优势能帮助产品放大吸引力，巩固用户优势形成正反馈循环，龙头公司确立行业的事实标准后，其他企业大多主动与其标准进行兼容适配，应用厂家可利用标准的网络外部性巩固其优势地位；最后，数据积累促进应用持续优化，高迁移成本、规模效应等特点同样促成应用软件形成"先发优势"。


图表2.13：掌握"标准"对于应用软件而言有多层次重要意义


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreH3M6VB7wneNlpQ0Xf0h87xso9BPrCnN2MvniaYpicl9GPQ74RI0MS4Kg%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：中金公司研究部


**2、AI应用尚处商用化早期阶段，场景落地端具备加速发展潜力**

**场景是应用实现商用化落地的关键，AI应用产业仍处场景发掘阶段。**从目前全球AI产业发展的现状来看，应用层的发展相较于模型层和硬件层都是相对滞后的，在ChatGPT涌现的一年多之后，全球范围的AI应用也再未出现又一同级别的"爆款"。无论是面向C端的工具类应用，还是面向B端的企业服务类应用，现阶段的AI应用在和真实使用场景和需求的贴合性、刚需性、实用性上仍有明显的提升空间，大部分的AI应用商业化都仍处于较为早期的场景探索和需求发掘阶段。

**对于商用化早期阶段的AI应用产业，先发者的相对优势或许并不那么可靠。**虽然如前文所述，"标准"能够为应用软件行业赋予明显的先发优势，但对于仍处发展早期阶段的AI应用产业而言，未来真正意义上AI应用的商业模式和场景范式尚未有定论，AI应用的"标准"尚未建立，因此先发者在现阶段建立积累的经验优势在未来也未必能够持续验证发挥。例如在AI和办公文档软件的结合领域，Notion AI是其中第一款推出的产品，其虽然在早期迅速积累了一批由AI功能吸引而来的新用户，但在后续数月就由于功能的单薄和场景的单一而又迅速流失了这部分用户。

**后发者可更多聚焦应用场景落地和商业模式优化，加速跑通AI应用商业闭环。**对于AI应用产业的先发者，其前期需要投入一定的精力和成本用于产品形态的搭建、应用场景的探索、商用模式的构想，而后再正式进入商业化落地阶段；而对于后发者而言，其在前期的探索和试错上的投入能够显著降低，可以更多地聚焦于真实应用场景的探索落地以及商用模式的优化跑通，在产品的技术架构的基本功能上学习先发者，而在用户体验和商用逻辑上力求超越先发者。


图表2.14：AI应用层的先发优势与后发优势


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreMUOhJQSf4guicUh7mGU1EIicnSjgQn0lcmLORQlg3LukhicNPVbpxszow%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：中金公司研究部


**3、中国AI应用产业发展的机遇和挑战**

**需求端来看，中国市场的个人和企业用户对于AI应用具有旺盛的需求。**2023年ChatGPT火爆以来，海内外应用厂商积极拥抱AI浪潮，AI应用持续加速繁荣。2Q23以来无论是通用场景还是垂类行业、C端还是B端都看到了AI应用的"百花齐放"，国内市场对AI应用的需求也持续爆发。在B端，激烈的竞争环境推动国内企业积极拥抱智能化，我国早已成为全球最大的工业机器人等先进智能生产工具装配市场，其全球占有率遥遥领先\[54\]。在C端，根据QuestMobile数据，2024年1月国内前10位AI应用APP聚合活跃用户规模达到5,376万，同比增长37倍\[55\]。展望未来，伴随AI应用功能持续成熟和完善，我们认为下游需求也有望持续快速释放，反哺国内AI应用实现落地加速。

**供给端来看，中国在移动互联网时代积累的应用产品经验，能够在AI应用时代继续发挥红利。**在过去十多年的移动互联网阶段，中国的互联网巨头们凭借对于本土市场用户需求的深刻理解实现了"弯道超车"，做出了众多"爆款"移动端APP，如社交领域的微信、电商领域的淘宝、零售领域的美团、短视频领域的抖音等，即使在海外市场，一些应用（如Tiktok）也能够凭借优异的用户体验成为流行应用。在工业生产领域，下游细分行业众多，各行业又有不同的工序，生产过程中不同的know-how以及对应产生的一线数据。由此导致工业领域的AI需求碎片（场景多单一产线开发成本高）、数据封闭（没有产业就没有数据），而中国庞大的工业体系不仅意味着AI所落地的场景更加多元成本更具规模优势，也意味着用于发展工业AI模型的数据体量更加丰富技术迭代能力更强，国内相关供应商早已在生产流程的各环节生根、壮大。而在未来的人工智能时代，未来国内外底层大模型的技术和性能差距有望持续收敛，用户体验或仍将是决定应用成功与否的关键，国内AI应用厂商也有望复刻过去移动互联网及工业互联网成功的经验，在海内外市场建立稳固的竞争力。

**在AI应用领域，优秀的中国应用厂商也有机会能够在国内外市场突破重围。**以国内市场为例，办公软件龙头金山办公凭借对本土用户需求的深刻理解持续迭代WPS Office产品并积累了广大活跃用户，其AI功能WPS AI推出之后，2024年3月底也正式开始灰度测试进入商业化进程。在功能上，其相比竞品Microsoft Copilot更为简单易用，支持内容生成、数据分析、文意理解等实用功能；在多端支持上，WPS AI能够支持PC和移动端，最大限度发挥WPS在移动端的优势；在商业落地上，WPS AI采用自下而上的商业策略，推广初期以积累客户为主要目的，而在积累AI功能的活跃用户后再循序渐进，实现更高效的商业化变现，有望在第一波商业化渗透速度上超过微软。在海外市场上，通过提供卓越的用户体验，一些应用已经成功实现了快速的市场突破，如国内大模型厂商Minimax的AI陪聊产品Talkie凭借更贴合角色的对话效果实现优于竞品的用户体验，海外活跃用户数已快速接近Character AI并有望实现逐步赶超。在工业应用领域，包括海康、大华等优秀的供应商早已具备全球竞争力。

**在AI终端领域，凭借领先的制造能力与品牌影响力，中国厂商有望引领AI时代。**进入2024年，人工智能发展逐渐下沉到端侧，我们观察到AIPC/AI手机发展加速：模型侧，从"暴力美学"大模型，到"删繁就简"轻量模型，轻量化移动模型发展迅速。谷歌Gemini Nano、Gemma、Meta Llama 2、Mixtral 8x-7B等引领移动模型轻量化发展趋势。AI带来的差异化体验在激烈的竞争环境下推动了下游落地的进程，中国企业具有领先的制造能力与品牌影响力，有望引领新一轮消费电子产业创新。根据IDC及国家统计局数据，2023年中国手机产量占全球比重超过75%，连续多年年产智能手机超过10亿台\[56\]。国产手机品牌市占率从2004年的0.02%提升至2023年的超过45%，国产PC品牌市占率也从2004年的9.53%提升至2023年的超过35%\[57\],\[58\]。当前在消费无人机、家用扫地机器人、智能音箱、智能门锁等新兴消费电子领域，中国品牌已在全球遥遥领先。在新兴的智能汽车赛道，中国也具备了引领全球的实力。中国的智能终端品牌已得到全球消费者认可。

**中国本土AI应用产业发展目前也面临诸多挑战，存在不利现状。**第一是在人才和创业者层面，实际上根据我们上文的分析，中国的AI人才已经成为全球产业力量中的重要部分，尤其是在AI应用赛道，产业中有大量具有中国背景的华人创业者，然而我们目前看到的是其中部分的华人创业者现阶段仍选择在海外发展，"回流"趋势目前并不明显。其中包括Luma、Lepton、HeyGen等全球范围内知名的AI应用创业公司，都是由华人团队组建，但业务目前基本都位于海外；第二是在应用场景层面，现阶段国内企业服务端AI应用发展相较海外相对滞后，在产品成熟度、商业化进程等层面，国内to B端AI应用厂商相对海外对标厂商基本都处于跟随态势，并未像to C端应用领域一样做出具有差异化的应用产品，同时在规模化商业落地层面的进度也落后于海外。

**原生市场环境以及基础设施现状成为主要限制因素。**从市场环境来看，国内目前to C和to B AI应用市场均存在一些问题：to C端来看，目前中国能够规模化推广的应用场景品类相较海外有限，因此对于需要开辟新场景、新需求的AI应用创业者而言，短期内海外市场可能更易于突破；to B端来看，中国过去SaaS企业服务的渗透率本身较低（中国SaaS市场规模仅占全球6%\[59\]，远低于中国GDP的占比），对于企业服务类应用的使用习惯、付费意愿相对弱于海外，因此在AI应用时代对于B端应用的重视程度也会相对滞后。而从基础设施来看，目前在海外市场的算力基础设施储备相较于国内也更为充分，获得同等算力资源的难度和成本相比于国内较低，具有更高性价比的算力基础设施也能够更好地支持AI应用发展。

**在终端市场，芯片依然是核心问题。**当前，一般认为AIPC、AI手机分别需要满足40TOPS和30TOPS的算力门槛，相关龙头芯片厂商均加快了对SoC及NPU等边缘侧芯片的算力提升速度。PC芯片方面，AMD、英特尔、高通新一代芯片算力能力高于国产芯片。手机芯片方面，根据AI Benchmark，高通、联发科、苹果手机SoC芯片算力跑分高于国产如展讯、海思等。受困于国内半导体产业当前遇到的诸多限制，目前国产芯片厂商仍明显落后，当前对外依赖程度依然较高。

**应用、模型、硬件三层之间相互牵引滋养，共同进步发展。**硬件层和模型层性能的提升促进应用层迭代优化，而应用层的强大能够滋养硬件层和模型层更好地发展，三者互相牵引滋养。例如，GPU的高并行计算能力可以加速深度学习模型的训练过程，模型可以通过剪枝算法减少参数量，提高推理速度的同时提高对硬件资源的利用效率。应用层反馈的需求也推动硬件层和模型层的发展。例如，在自动驾驶领域的高实时性能要求推动了GPU和FPGA等硬件技术的发展，同时也促进了深度学习模型在目标检测和路径规划等方面的优化。


图表2.15：应用层、模型层、硬件层三层之间的相互促进关系


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_png%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBre8CN2ftmDn2dAS35XdtSsfDuAMr2uQ0lq7LYry6NBWbYmQfybv14JUg%2F640%3Fwx_fmt%3Dpng%26from%3Dappmsg)


资料来源：各公司官网，中金公司研究部


\[1\]https://www.gov.cn/xinwen/2023-03/19/content_5747420.htm

\[2\]https://mp.weixin.qq.com/s/AOzbcFkmkaEAw55QCJt31g

\[3\]《第四范式招股书》，2023年。

\[4\]https://mp.weixin.qq.com/s/sY1f1t6GeWwp0Qy1Wo1V1A

\[5\]《AutoML成就指数级增长-感知、认知、决策算法布局提升企业决策水平》，2021年。

\[6\]探索人工智能新前沿：中国经济再迎6000亿美元机遇》，2022年。

\[7\]STEM是科学（Science）、技术（Technology）、工程（Engineering）、数学（Mathematics）四门学科英文首字母的缩写。

\[8\]http://www.mohrss.gov.cn/SYrlzyhshbzb/dongtaixinwen/buneiyaowen/rsxw/202312/t20231220_510820.html

\[9\]http://www.news.cn/20240529/779a245d71564834a15e68faa70a399a/c.html

\[10\]https://www.statista.com/statistics/272014/global-social-networks-ranked-by-number-of-users/

\[11\]Epoch AI统计的"知名模型"是指在AI或机器学习生态系统中具有影响力的模型。统计数据库来源https://epochai.org/data/epochdb/table

\[12\]此处，若模型作者中同时包含美国学者和中国学者，则既算美国的模型、也算中国的模型，因此中美发布的模型数量可能存在交叉。

\[13\]Dylan Patel and Gerald Wong, GPT-4 Architecture, Infrastructure, Training Dataset, Costs, Vision, MoE, July 2023. Source: https://www.semianalysis.com/p/gpt-4-architecture-infrastructure

\[14\]Xiaozhe Ren et al., PanGu-Σ: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing, March 2023.

\[15\]https://zhipuai.cn/devday

\[16\]https://omdia.tech.informa.com/-/media/tech/omdia/marketing/commissioned-research/pdfs/china-ai-frameworks-market-report-2023

\[17\]https://www.bis.doc.gov/index.php/policy-guidance/advanced-computing-and-semiconductor-manufacturing-items-controls-to-prc

\[18\]Koch, Bernard , et al. Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research. (2021). https://arxiv.org/pdf/2112.01716v1

\[19\]https://www.199it.com/archives/1605238.html

\[20\]Suriya Gunasekar, et al. Textbooks Are All You Need, Oct 2023. https://arxiv.org/abs/2306.11644

\[21\]https://www.databricks.com/blog/llm-training-and-inference-intel-gaudi2-ai-accelerators

\[22\]David E. Rumelhart, et al., Learning representations by back-propagating errors, October 1986.

\[23\]Yann Lecun, et al., Gradient-based learning applied to document recognition, November 1998.

\[24\]Geoffrey E. Hinton, et al., A Fast Learning Algorithm for Deep Belief Nets, July 2006.

\[25\]J. G. White, et al., The structure of the nervous system of the nematode Caenorhabditis elegans, November 1986.

\[26\]Steven J Cook, et al., Whole-animal connectomes of both Caenorhabditis elegans sexes, July 2019.

\[27\]Ray Perrault, et al., Artificial Intelligence Index Report 2024, April 2024.

\[28\]https://karpathy.ai/stateofgpt.pdf

\[29\]https://iliyaml.github.io/about/

\[30\]https://www.nvidia.com/en-us/on-demand/session/computex24-keynote/?playlistId=playList-5d17c33f-65f5-4fb1-9fed-bc5b7f4dec44

\[31\]Jared Kaplan, et al., Scaling laws for neural language models, January 2020.

\[32\]Jordan Hoffmann, et al., Training Compute-Optimal Large Language Models,March 2022.

\[33\]下文中提到的"理解"、"感觉"、"人类心智"等术语在学术上无统一的定义，相对抽象，因此或是导致学者观点分歧的原因之一

\[34\]Pablo Villalobos, et al., Will we run out of data? An analysis of the limits of scaling datasets in Machine Learning, October 2022.

\[35\]Chen Liang, et al, No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models, February 2022.

\[36\]Conglong Li, et al. The Stability-Efficiency Dilemma: Investigating Sequence Length Warmup for Training GPT Models, August 2021.

\[37\]Carlos E. Jimenez, et al., SWE-bench: Can Language Models Resolve Real-World GitHub Issues?, October 2023.

\[38\]Anna Dawid, Yann LeCun, Introduction to Latent Variable Energy-Based Models: A Path Towards Autonomous Machine Intelligence, June 2023.

\[39\]Fei-Fei Li and John Etchemendy, No, Today's AI Isn't Sentient. Here's How We Know, May 2024.

\[40\]Romal Thoppilan, et al., LaMDA: Language Models for Dialog Applications, January 2022.

\[41\]Xu Guo and Yiqiang Chen, Generative AI for Synthetic Data Generation: Methods, Challenges and the Future, March 2024.

\[42\]Artyom Eliseev, Denis Mazur, Fast Inference of Mixture-of-Experts Language Models with Offloading, December 2023.

\[43\]Antonio Polino, et al., Model compression via distillation and quantization, February 2018.

\[44\]Strachan, J.W.A., Albergo, D., Borghini, G., et al., Testing theory of mind in large language models and humans, Nat Hum Behav, May 2024.

\[45\]https://wallstreetcn.com/articles/3709410

\[46\]https://new.qq.com/rain/a/20240306A04WQJ00

\[47\]https://www.zhihu.com/question/629230332/answer/3278779348

\[48\]https://www.dwarkeshpatel.com/p/dario-amodei

\[49\]Geng, Xinyang, Hao Liu, Openllama: An open reproduction of llama, 2023.

\[50\]Rohan Taori, et al., Alpaca: A Strong, Replicable Instruction-Following Model, March 2023.

\[51\]Arnav Gudibande, et al., The False Promise of Imitating Proprietary LLMs, May 2023.

\[52\]Christensen L R, Ghose A, Mathur D. The Economic Impact of Open Source Software on Competition, Innovation and Development in India, 2020.

\[53\]Peter Kollock, The economies of online cooperation: Gifts and public goods in cyberspace, 1999.

\[54\]https://ifr.org/ifr-press-releases/news/china-overtakes-usa-in-robot-density

\[55\]https://www.questmobile.com.cn/research/report/1767395734913650690

\[56\]https://www.miit.gov.cn/gxsj/tjfx/dzxx/art/2024/art_973024044030402ab5e742405126bc9e.html

\[57\]https://www.idc.com/getdoc.jsp?containerId=prCHC51776924

\[58\]https://www.idc.com/getdoc.jsp?containerId=prUS51604623

\[59\]IDC，https://www.idc.com/getdoc.jsp?containerId=prCHC50937223


**Source**


**文章来源**


本文摘自：2024年6月27日已经发布的《第二章 中国AI发展面临的挑战与应对之道》

彭虎 分析员 SAC 执证编号：S0080521020001 SFC CE Ref：BRE806

赵丽萍 分析员 SAC 执证编号：S0080516060004 SFC CE Ref：BEH709

于钟海 分析员 SAC 执证编号：S0080518070011 SFC CE Ref：BOP246

陈昊 分析员 SAC 执证编号：S0080520120009 SFC CE Ref：BQS925

成乔升 分析员 SAC 执证编号：S0080521060004

王之昊 分析员 SAC 执证编号：S0080522050001 SFC CE Ref：BSS168

温晗静 分析员 SAC 执证编号：S0080521070003 SFC CE Ref：BSJ666

魏鹳霏 分析员 SAC 执证编号：S0080523060019 SFC CE Ref：BSX734

李诗雯 分析员 SAC 执证编号：S0080521070008 SFC CE Ref：BRG963

韩蕊 分析员 SAC 执证编号：S0080523070010

黄天擎 分析员 SAC 执证编号：S0080523060005 SFC CE Ref：BTL932

游航 分析员 SAC 执证编号：S0080523010001 SFC CE Ref：BTI822

孔杨 联系人 SAC 执证编号：S0080122110018

王倩蕾 联系人 SAC 执证编号：S0080122090111

何欣怡 联系人 SAC 执证编号：S0080123070095


**Legal Disclaimer**


**法律声明**


特别提示

本公众号不是中国国际金融股份有限公司（下称"中金公司"）研究报告的发布平台。本公众号只是转发中金公司已发布研究报告的部分观点，订阅者若使用本公众号所载资料，有可能会因缺乏对完整报告的了解或缺乏相关的解读而对资料中的关键假设、评级、目标价等内容产生理解上的歧义。订阅者如使用本资料，须寻求专业投资顾问的指导及解读。

本公众号所载信息、意见不构成所述证券或金融工具买卖的出价或征价，评级、目标价、估值、盈利预测等分析判断亦不构成对具体证券或金融工具在具体价位、具体时点、具体市场表现的投资建议。该等信息、意见在任何时候均不构成对任何人的具有针对性的、指导具体投资的操作意见，订阅者应当对本公众号中的信息和意见进行评估，根据自身情况自主做出投资决策并自行承担投资风险。

中金公司对本公众号所载资料的准确性、可靠性、时效性及完整性不作任何明示或暗示的保证。对依据或者使用本公众号所载资料所造成的任何后果，中金公司及/或其关联人员均不承担任何形式的责任。

本公众号仅面向中金公司中国内地客户，任何不符合前述条件的订阅者，敬请订阅前自行评估接收订阅内容的适当性。订阅本公众号不构成任何合同或承诺的基础，中金公司不因任何单纯订阅本公众号的行为而将订阅人视为中金公司的客户。

一般声明

本公众号仅是转发中金公司已发布报告的部分观点，所载盈利预测、目标价格、评级、估值等观点的给予是基于一系列的假设和前提条件，订阅者只有在了解相关报告中的全部信息基础上，才可能对相关观点形成比较全面的认识。如欲了解完整观点，应参见中金研究网站（http://research.cicc.com）所载完整报告。

本资料较之中金公司正式发布的报告存在延时转发的情况，并有可能因报告发布日之后的情势或其他因素的变更而不再准确或失效。本资料所载意见、评估及预测仅为报告出具日的观点和判断。该等意见、评估及预测无需通知即可随时更改。证券或金融工具的价格或价值走势可能受各种因素影响，过往的表现不应作为日后表现的预示和担保。在不同时期，中金公司可能会发出与本资料所载意见、评估及预测不一致的研究报告。中金公司的销售人员、交易人员以及其他专业人士可能会依据不同假设和标准、采用不同的分析方法而口头或书面发表与本资料意见不一致的市场评论和/或交易观点。

在法律许可的情况下，中金公司可能与本资料中提及公司正在建立或争取建立业务关系或服务关系。因此，订阅者应当考虑到中金公司及/或其相关人员可能存在影响本资料观点客观性的潜在利益冲突。与本资料相关的披露信息请访http://research.cicc.com/disclosure_cn，亦可参见近期已发布的关于相关公司的具体研究报告。

本订阅号是由中金公司研究部建立并维护的官方订阅号。本订阅号中所有资料的版权均为中金公司所有，未经书面许可任何机构和个人不得以任何形式转发、转载、翻版、复制、刊登、发表、修改、仿制或引用本订阅号中的内容。


![](https://cubox.pro/c/filters:no_upscale()?imageUrl=https%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FfzHRVN3sYsiboeF7HNibvibs4HxZicnBEBreh00KBCE9D3frpu3JVzuepBqkicicptnc3pXkEQvNK9fRvYrhURGuLC4g%2F640%3Fwx_fmt%3Djpeg%26from%3Dappmsg)


[跳转到 Cubox 查看](https://cubox.pro/my/card?id=7206555846191353274)
